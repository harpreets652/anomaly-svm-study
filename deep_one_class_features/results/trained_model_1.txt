Using SGD, 64 batch size, 2 epochs, without normalization and only optimizing compactness loss


Reference model built
Secondary model built
Total number of iterations: 664
Iteration 0, total loss: 3.7521848678588867, discriminative loss: 14.715536117553711
Iteration 1, total loss: 1.011538028717041, discriminative loss: 7.183908462524414
Iteration 2, total loss: 1.0076459646224976, discriminative loss: 7.1762895584106445
Iteration 3, total loss: 1.0064427852630615, discriminative loss: 7.249814033508301
Iteration 4, total loss: 1.0057777166366577, discriminative loss: 7.156880855560303
Iteration 5, total loss: 1.0051149129867554, discriminative loss: 7.488752365112305
Iteration 6, total loss: 1.0053776502609253, discriminative loss: 7.180891990661621
Iteration 7, total loss: 1.0042365789413452, discriminative loss: 6.936239242553711
Iteration 8, total loss: 1.003885269165039, discriminative loss: 7.223756313323975
Iteration 9, total loss: 1.0035269260406494, discriminative loss: 7.16557502746582
Iteration 10, total loss: 1.0046035051345825, discriminative loss: 7.143733978271484
Iteration 11, total loss: 1.0038419961929321, discriminative loss: 7.178157806396484
Iteration 12, total loss: 1.0043394565582275, discriminative loss: 7.231014728546143
Iteration 13, total loss: 1.003834843635559, discriminative loss: 7.209550380706787
Iteration 14, total loss: 1.0036081075668335, discriminative loss: 7.265549182891846
Iteration 15, total loss: 1.0035700798034668, discriminative loss: 7.164685249328613
Iteration 16, total loss: 1.0032168626785278, discriminative loss: 7.170468807220459
Iteration 17, total loss: 1.0026293992996216, discriminative loss: 7.111781120300293
Iteration 18, total loss: 1.0025951862335205, discriminative loss: 7.217461109161377
Iteration 19, total loss: 1.0026895999908447, discriminative loss: 7.052105903625488
Iteration 20, total loss: 1.0024908781051636, discriminative loss: 7.178797245025635
Iteration 21, total loss: 1.0021775960922241, discriminative loss: 7.104465484619141
Iteration 22, total loss: 1.0020637512207031, discriminative loss: 7.205400466918945
Iteration 23, total loss: 1.0021241903305054, discriminative loss: 7.106727600097656
Iteration 24, total loss: 1.0018653869628906, discriminative loss: 7.113400936126709
Iteration 25, total loss: 1.0019676685333252, discriminative loss: 7.086345672607422
Iteration 26, total loss: 1.0021103620529175, discriminative loss: 7.173624038696289
Iteration 27, total loss: 1.0015864372253418, discriminative loss: 7.201526641845703
Iteration 28, total loss: 1.0020887851715088, discriminative loss: 7.065726280212402
Iteration 29, total loss: 1.0017075538635254, discriminative loss: 7.248887538909912
Iteration 30, total loss: 1.0016182661056519, discriminative loss: 7.2014875411987305
Iteration 31, total loss: 1.0024030208587646, discriminative loss: 7.123190879821777
Iteration 32, total loss: 1.0018362998962402, discriminative loss: 7.171226978302002
Iteration 33, total loss: 1.0015370845794678, discriminative loss: 7.290040016174316
Iteration 34, total loss: 1.0015321969985962, discriminative loss: 7.104549407958984
Iteration 35, total loss: 1.0022794008255005, discriminative loss: 7.181455612182617
Iteration 36, total loss: 1.0012845993041992, discriminative loss: 7.099595069885254
Iteration 37, total loss: 1.0012694597244263, discriminative loss: 7.179623603820801
Iteration 38, total loss: 1.0019505023956299, discriminative loss: 7.214875221252441
Iteration 39, total loss: 1.0012450218200684, discriminative loss: 7.107300758361816
Iteration 40, total loss: 1.0013597011566162, discriminative loss: 7.320685386657715
Iteration 41, total loss: 1.0012452602386475, discriminative loss: 7.233391761779785
Iteration 42, total loss: 1.0010839700698853, discriminative loss: 7.171103477478027
Iteration 43, total loss: 1.00166654586792, discriminative loss: 7.124383926391602
Iteration 44, total loss: 1.0013269186019897, discriminative loss: 7.156777381896973
Iteration 45, total loss: 1.001642107963562, discriminative loss: 7.121466636657715
Iteration 46, total loss: 1.0010182857513428, discriminative loss: 7.066375732421875
Iteration 47, total loss: 1.0009880065917969, discriminative loss: 7.195809841156006
Iteration 48, total loss: 1.001266360282898, discriminative loss: 7.293087005615234
Iteration 49, total loss: 1.0008506774902344, discriminative loss: 7.184011459350586
Iteration 50, total loss: 1.0010578632354736, discriminative loss: 7.221434593200684
Iteration 51, total loss: 1.000751256942749, discriminative loss: 7.217502593994141
Iteration 52, total loss: 1.0010370016098022, discriminative loss: 7.153658390045166
Iteration 53, total loss: 1.0007266998291016, discriminative loss: 6.965324401855469
Iteration 54, total loss: 1.0009106397628784, discriminative loss: 7.1724724769592285
Iteration 55, total loss: 1.0013843774795532, discriminative loss: 7.21112585067749
Iteration 56, total loss: 1.0006446838378906, discriminative loss: 6.9495954513549805
Iteration 57, total loss: 1.0009454488754272, discriminative loss: 7.308744430541992
Iteration 58, total loss: 1.0012977123260498, discriminative loss: 7.014227390289307
Iteration 59, total loss: 1.0009186267852783, discriminative loss: 7.224400043487549
Iteration 60, total loss: 1.000697135925293, discriminative loss: 7.064679145812988
Iteration 61, total loss: 1.000944972038269, discriminative loss: 7.146509170532227
Iteration 62, total loss: 1.0010234117507935, discriminative loss: 7.097181797027588
Iteration 63, total loss: 1.0009726285934448, discriminative loss: 7.133393287658691
Iteration 64, total loss: 1.0006253719329834, discriminative loss: 7.058445453643799
Iteration 65, total loss: 1.0006417036056519, discriminative loss: 7.190815448760986
Iteration 66, total loss: 1.0008372068405151, discriminative loss: 7.218539237976074
Iteration 67, total loss: 1.0007277727127075, discriminative loss: 7.2918500900268555
Iteration 68, total loss: 1.000937581062317, discriminative loss: 7.052454948425293
Iteration 69, total loss: 1.0006054639816284, discriminative loss: 7.115200996398926
Iteration 70, total loss: 1.000667929649353, discriminative loss: 7.134923458099365
Iteration 71, total loss: 1.001002550125122, discriminative loss: 7.128829479217529
Iteration 72, total loss: 1.000516653060913, discriminative loss: 7.012861251831055
Iteration 73, total loss: 1.000744342803955, discriminative loss: 7.182795524597168
Iteration 74, total loss: 1.0007197856903076, discriminative loss: 7.049323081970215
Iteration 75, total loss: 1.0005948543548584, discriminative loss: 7.00391960144043
Iteration 76, total loss: 1.0007953643798828, discriminative loss: 7.198437213897705
Iteration 77, total loss: 1.0005921125411987, discriminative loss: 7.111972808837891
Iteration 78, total loss: 1.0010563135147095, discriminative loss: 7.239937782287598
Iteration 79, total loss: 1.0007890462875366, discriminative loss: 6.929698944091797
Iteration 80, total loss: 1.0007776021957397, discriminative loss: 7.171907424926758
Iteration 81, total loss: 1.000717282295227, discriminative loss: 7.158465385437012
Iteration 82, total loss: 1.000476360321045, discriminative loss: 7.276947021484375
Iteration 83, total loss: 1.0004862546920776, discriminative loss: 7.220589637756348
Iteration 84, total loss: 1.0005043745040894, discriminative loss: 7.128000736236572
Iteration 85, total loss: 1.0006613731384277, discriminative loss: 7.13330602645874
Iteration 86, total loss: 1.0006791353225708, discriminative loss: 7.097421646118164
Iteration 87, total loss: 1.0007067918777466, discriminative loss: 7.187156677246094
Iteration 88, total loss: 1.0005887746810913, discriminative loss: 7.056382179260254
Iteration 89, total loss: 1.0005537271499634, discriminative loss: 7.141632080078125
Iteration 90, total loss: 1.0005148649215698, discriminative loss: 7.273312091827393
Iteration 91, total loss: 1.0004234313964844, discriminative loss: 7.208674907684326
Iteration 92, total loss: 1.0004909038543701, discriminative loss: 7.1926727294921875
Iteration 93, total loss: 1.0005489587783813, discriminative loss: 7.206844806671143
Iteration 94, total loss: 1.0006892681121826, discriminative loss: 7.190065383911133
Iteration 95, total loss: 1.000451683998108, discriminative loss: 7.041918754577637
Iteration 96, total loss: 1.0008307695388794, discriminative loss: 7.145603179931641
Iteration 97, total loss: 1.0003514289855957, discriminative loss: 7.224077224731445
Iteration 98, total loss: 1.0005245208740234, discriminative loss: 7.158480644226074
Iteration 99, total loss: 1.0006999969482422, discriminative loss: 7.354482173919678
Iteration 100, total loss: 1.0004788637161255, discriminative loss: 7.149454116821289
Iteration 101, total loss: 1.0003327131271362, discriminative loss: 7.156101226806641
Iteration 102, total loss: 1.0004476308822632, discriminative loss: 7.180570602416992
Iteration 103, total loss: 1.0003186464309692, discriminative loss: 7.043929100036621
Iteration 104, total loss: 1.0004369020462036, discriminative loss: 7.115106105804443
Iteration 105, total loss: 1.0003926753997803, discriminative loss: 7.284055233001709
Iteration 106, total loss: 1.0005097389221191, discriminative loss: 7.166529178619385
Iteration 107, total loss: 1.0005196332931519, discriminative loss: 7.159959316253662
Iteration 108, total loss: 1.0004974603652954, discriminative loss: 7.083423137664795
Iteration 109, total loss: 1.000396490097046, discriminative loss: 7.112754821777344
Iteration 110, total loss: 1.0003913640975952, discriminative loss: 7.207239627838135
Iteration 111, total loss: 1.000407099723816, discriminative loss: 7.214022636413574
Iteration 112, total loss: 1.000328540802002, discriminative loss: 7.151847839355469
Iteration 113, total loss: 1.000698208808899, discriminative loss: 7.100804328918457
Iteration 114, total loss: 1.0005451440811157, discriminative loss: 7.15994930267334
Iteration 115, total loss: 1.000301480293274, discriminative loss: 6.994214057922363
Iteration 116, total loss: 1.0005550384521484, discriminative loss: 7.103543281555176
Iteration 117, total loss: 1.0007078647613525, discriminative loss: 7.118791580200195
Iteration 118, total loss: 1.0003063678741455, discriminative loss: 7.097113609313965
Iteration 119, total loss: 1.000488519668579, discriminative loss: 7.145694732666016
Iteration 120, total loss: 1.0004360675811768, discriminative loss: 7.0647101402282715
Iteration 121, total loss: 1.0004116296768188, discriminative loss: 7.073026657104492
Iteration 122, total loss: 1.000501036643982, discriminative loss: 7.005988121032715
Iteration 123, total loss: 1.0004618167877197, discriminative loss: 7.108964920043945
Iteration 124, total loss: 1.0002564191818237, discriminative loss: 7.173827171325684
Iteration 125, total loss: 1.0004054307937622, discriminative loss: 7.235167503356934
Iteration 126, total loss: 1.000261664390564, discriminative loss: 7.117206573486328
Iteration 127, total loss: 1.0006768703460693, discriminative loss: 7.107531547546387
Iteration 128, total loss: 1.0005215406417847, discriminative loss: 7.125823974609375
Iteration 129, total loss: 1.0004149675369263, discriminative loss: 7.197657108306885
Iteration 130, total loss: 1.0004137754440308, discriminative loss: 7.171274185180664
Iteration 131, total loss: 1.0003796815872192, discriminative loss: 7.1582183837890625
Iteration 132, total loss: 1.00026273727417, discriminative loss: 7.184486389160156
Iteration 133, total loss: 1.0003364086151123, discriminative loss: 7.033576011657715
Iteration 134, total loss: 1.0002208948135376, discriminative loss: 7.071699142456055
Iteration 135, total loss: 1.0003538131713867, discriminative loss: 7.1204833984375
Iteration 136, total loss: 1.000252604484558, discriminative loss: 7.214638710021973
Iteration 137, total loss: 1.0003830194473267, discriminative loss: 7.25466251373291
Iteration 138, total loss: 1.0003397464752197, discriminative loss: 7.048313140869141
Iteration 139, total loss: 1.000349760055542, discriminative loss: 7.143575668334961
Iteration 140, total loss: 1.0007519721984863, discriminative loss: 7.24688196182251
Iteration 141, total loss: 1.0002703666687012, discriminative loss: 7.044054985046387
Iteration 142, total loss: 1.00029456615448, discriminative loss: 7.155755043029785
Iteration 143, total loss: 1.0003323554992676, discriminative loss: 7.234537124633789
Iteration 144, total loss: 1.0002541542053223, discriminative loss: 7.293800354003906
Iteration 145, total loss: 1.0003527402877808, discriminative loss: 7.186750411987305
Iteration 146, total loss: 1.000322699546814, discriminative loss: 7.275814056396484
Iteration 147, total loss: 1.000258445739746, discriminative loss: 7.141183376312256
Iteration 148, total loss: 1.000287413597107, discriminative loss: 7.067277908325195
Iteration 149, total loss: 1.0003020763397217, discriminative loss: 7.21145486831665
Iteration 150, total loss: 1.0003094673156738, discriminative loss: 6.977925777435303
Iteration 151, total loss: 1.0002787113189697, discriminative loss: 7.049763202667236
Iteration 152, total loss: 1.0002901554107666, discriminative loss: 7.030888080596924
Iteration 153, total loss: 1.0002902746200562, discriminative loss: 7.008910179138184
Iteration 154, total loss: 1.0003870725631714, discriminative loss: 7.242372512817383
Iteration 155, total loss: 1.0003098249435425, discriminative loss: 7.168941974639893
Iteration 156, total loss: 1.0002503395080566, discriminative loss: 7.149420738220215
Iteration 157, total loss: 1.0002601146697998, discriminative loss: 7.250070571899414
Iteration 158, total loss: 1.0002552270889282, discriminative loss: 6.965041160583496
Iteration 159, total loss: 1.0003553628921509, discriminative loss: 7.075555801391602
Iteration 160, total loss: 1.0006413459777832, discriminative loss: 7.0277910232543945
Iteration 161, total loss: 1.0002682209014893, discriminative loss: 7.246848106384277
Iteration 162, total loss: 1.0002763271331787, discriminative loss: 7.185920715332031
Iteration 163, total loss: 1.000267505645752, discriminative loss: 7.221394062042236
Iteration 164, total loss: 1.0001468658447266, discriminative loss: 7.096950054168701
Iteration 165, total loss: 1.000331163406372, discriminative loss: 7.265336513519287
Iteration 166, total loss: 1.0002200603485107, discriminative loss: 7.176840782165527
Iteration 167, total loss: 1.0002856254577637, discriminative loss: 7.102114677429199
Iteration 168, total loss: 1.0003015995025635, discriminative loss: 7.152828693389893
Iteration 169, total loss: 1.0003058910369873, discriminative loss: 7.163674831390381
Iteration 170, total loss: 1.0002435445785522, discriminative loss: 7.116167068481445
Iteration 171, total loss: 1.0003836154937744, discriminative loss: 7.226487159729004
Iteration 172, total loss: 1.0002580881118774, discriminative loss: 7.327287673950195
Iteration 173, total loss: 1.0005766153335571, discriminative loss: 7.138212203979492
Iteration 174, total loss: 1.0003544092178345, discriminative loss: 7.122446537017822
Iteration 175, total loss: 1.0001938343048096, discriminative loss: 7.150688171386719
Iteration 176, total loss: 1.0002496242523193, discriminative loss: 7.155117988586426
Iteration 177, total loss: 1.0001517534255981, discriminative loss: 7.208867073059082
Iteration 178, total loss: 1.000200867652893, discriminative loss: 7.24149227142334
Iteration 179, total loss: 1.0002983808517456, discriminative loss: 7.158003807067871
Iteration 180, total loss: 1.0004771947860718, discriminative loss: 7.182734489440918
Iteration 181, total loss: 1.0003302097320557, discriminative loss: 7.252040863037109
Iteration 182, total loss: 1.0001951456069946, discriminative loss: 7.209569931030273
Iteration 183, total loss: 1.0003305673599243, discriminative loss: 7.130490303039551
Iteration 184, total loss: 1.0004100799560547, discriminative loss: 7.181619644165039
Iteration 185, total loss: 1.0002299547195435, discriminative loss: 7.170249938964844
Iteration 186, total loss: 1.0002565383911133, discriminative loss: 7.162690162658691
Iteration 187, total loss: 1.0002096891403198, discriminative loss: 7.095131874084473
Iteration 188, total loss: 1.0007423162460327, discriminative loss: 7.016061782836914
Iteration 189, total loss: 1.0001585483551025, discriminative loss: 7.0890655517578125
Iteration 190, total loss: 1.0004693269729614, discriminative loss: 7.107713222503662
Iteration 191, total loss: 1.0003072023391724, discriminative loss: 7.116572380065918
Iteration 192, total loss: 1.0003231763839722, discriminative loss: 7.1952056884765625
Iteration 193, total loss: 1.0003726482391357, discriminative loss: 7.015558242797852
Iteration 194, total loss: 1.0005959272384644, discriminative loss: 7.249898910522461
Iteration 195, total loss: 1.0002883672714233, discriminative loss: 7.254938125610352
Iteration 196, total loss: 1.0003187656402588, discriminative loss: 7.032434463500977
Iteration 197, total loss: 1.0003907680511475, discriminative loss: 7.240704536437988
Iteration 198, total loss: 1.0001705884933472, discriminative loss: 6.977080345153809
Iteration 199, total loss: 1.0001834630966187, discriminative loss: 7.230271816253662
Iteration 200, total loss: 1.0001708269119263, discriminative loss: 7.197913646697998
Iteration 201, total loss: 1.0001956224441528, discriminative loss: 7.302220821380615
Iteration 202, total loss: 1.0003503561019897, discriminative loss: 7.2217206954956055
Iteration 203, total loss: 1.0006507635116577, discriminative loss: 7.030099868774414
Iteration 204, total loss: 1.0001516342163086, discriminative loss: 7.211708068847656
Iteration 205, total loss: 1.0001331567764282, discriminative loss: 7.318793296813965
Iteration 206, total loss: 1.000252604484558, discriminative loss: 7.087882995605469
Iteration 207, total loss: 1.0005346536636353, discriminative loss: 7.084650039672852
Iteration 208, total loss: 1.0001684427261353, discriminative loss: 7.233608245849609
Iteration 209, total loss: 1.0002431869506836, discriminative loss: 7.254587173461914
Iteration 210, total loss: 1.0001667737960815, discriminative loss: 7.118911266326904
Iteration 211, total loss: 1.0001081228256226, discriminative loss: 7.28349494934082
Iteration 212, total loss: 1.0001335144042969, discriminative loss: 7.14687442779541
Iteration 213, total loss: 1.000311017036438, discriminative loss: 7.169677734375
Iteration 214, total loss: 1.0001425743103027, discriminative loss: 7.4120097160339355
Iteration 215, total loss: 1.0001524686813354, discriminative loss: 7.209495544433594
Iteration 216, total loss: 1.0001482963562012, discriminative loss: 7.003126621246338
Iteration 217, total loss: 1.0001355409622192, discriminative loss: 7.133049964904785
Iteration 218, total loss: 1.00020170211792, discriminative loss: 7.105386734008789
Iteration 219, total loss: 1.0001791715621948, discriminative loss: 7.092068672180176
Iteration 220, total loss: 1.0001180171966553, discriminative loss: 7.219668388366699
Iteration 221, total loss: 1.000361442565918, discriminative loss: 7.090848922729492
Iteration 222, total loss: 1.0002515316009521, discriminative loss: 7.189850807189941
Iteration 223, total loss: 1.000126600265503, discriminative loss: 7.192946434020996
Iteration 224, total loss: 1.0004421472549438, discriminative loss: 7.070674419403076
Iteration 225, total loss: 1.0002880096435547, discriminative loss: 7.2120361328125
Iteration 226, total loss: 1.0000922679901123, discriminative loss: 7.154479026794434
Iteration 227, total loss: 1.0003570318222046, discriminative loss: 7.053764343261719
Iteration 228, total loss: 1.0001652240753174, discriminative loss: 7.00490665435791
Iteration 229, total loss: 1.0003482103347778, discriminative loss: 7.133322715759277
Iteration 230, total loss: 1.0001115798950195, discriminative loss: 7.296695709228516
Iteration 231, total loss: 1.0003646612167358, discriminative loss: 6.995703220367432
Iteration 232, total loss: 1.000147819519043, discriminative loss: 7.080267906188965
Iteration 233, total loss: 1.000167965888977, discriminative loss: 7.315889358520508
Iteration 234, total loss: 1.0000911951065063, discriminative loss: 7.310190200805664
Iteration 235, total loss: 1.0001243352890015, discriminative loss: 7.085088729858398
Iteration 236, total loss: 1.0004158020019531, discriminative loss: 7.311799049377441
Iteration 237, total loss: 1.00010085105896, discriminative loss: 7.154176712036133
Iteration 238, total loss: 1.0001134872436523, discriminative loss: 7.058946132659912
Iteration 239, total loss: 1.0003736019134521, discriminative loss: 7.109230041503906
Iteration 240, total loss: 1.0001124143600464, discriminative loss: 6.987260818481445
Iteration 241, total loss: 1.000093698501587, discriminative loss: 7.083652019500732
Iteration 242, total loss: 1.0001357793807983, discriminative loss: 7.139427185058594
Iteration 243, total loss: 1.000100016593933, discriminative loss: 7.231243133544922
Iteration 244, total loss: 1.0001941919326782, discriminative loss: 7.356747627258301
Iteration 245, total loss: 1.000079870223999, discriminative loss: 7.170426368713379
Iteration 246, total loss: 1.0001202821731567, discriminative loss: 7.267934322357178
Iteration 247, total loss: 1.000141978263855, discriminative loss: 7.184207439422607
Iteration 248, total loss: 1.0001752376556396, discriminative loss: 7.153314590454102
Iteration 249, total loss: 1.000095248222351, discriminative loss: 7.373291969299316
Iteration 250, total loss: 1.0002703666687012, discriminative loss: 7.187683582305908
Iteration 251, total loss: 1.00038743019104, discriminative loss: 7.091743469238281
Iteration 252, total loss: 1.0000979900360107, discriminative loss: 7.17107629776001
Iteration 253, total loss: 1.000179648399353, discriminative loss: 7.2535624504089355
Iteration 254, total loss: 1.0001500844955444, discriminative loss: 7.261291027069092
Iteration 255, total loss: 1.0000970363616943, discriminative loss: 7.115309715270996
Iteration 256, total loss: 1.0002402067184448, discriminative loss: 7.1943559646606445
Iteration 257, total loss: 1.0003129243850708, discriminative loss: 7.169419288635254
Iteration 258, total loss: 1.0001099109649658, discriminative loss: 7.320969104766846
Iteration 259, total loss: 1.0005441904067993, discriminative loss: 7.259636402130127
Iteration 260, total loss: 1.0000978708267212, discriminative loss: 7.225179672241211
Iteration 261, total loss: 1.0000953674316406, discriminative loss: 7.3232502937316895
Iteration 262, total loss: 1.0001306533813477, discriminative loss: 7.066019058227539
Iteration 263, total loss: 1.0000874996185303, discriminative loss: 7.167794704437256
Iteration 264, total loss: 1.0001791715621948, discriminative loss: 7.038047790527344
Iteration 265, total loss: 1.0002236366271973, discriminative loss: 7.026419162750244
Iteration 266, total loss: 1.0001453161239624, discriminative loss: 7.174994468688965
Iteration 267, total loss: 1.0003612041473389, discriminative loss: 7.002880096435547
Iteration 268, total loss: 1.0001589059829712, discriminative loss: 6.976587295532227
Iteration 269, total loss: 1.0002793073654175, discriminative loss: 6.986181259155273
Iteration 270, total loss: 1.0002788305282593, discriminative loss: 7.141297340393066
Iteration 271, total loss: 1.0001386404037476, discriminative loss: 7.077478408813477
Iteration 272, total loss: 1.000099778175354, discriminative loss: 6.989013195037842
Iteration 273, total loss: 1.0002491474151611, discriminative loss: 7.248043060302734
Iteration 274, total loss: 1.0001846551895142, discriminative loss: 7.209768295288086
Iteration 275, total loss: 1.000125527381897, discriminative loss: 7.155062198638916
Iteration 276, total loss: 1.000148892402649, discriminative loss: 6.9967145919799805
Iteration 277, total loss: 1.0000901222229004, discriminative loss: 7.297069549560547
Iteration 278, total loss: 1.000482201576233, discriminative loss: 7.110630035400391
Iteration 279, total loss: 1.0001111030578613, discriminative loss: 7.064344882965088
Iteration 280, total loss: 1.0001109838485718, discriminative loss: 7.234967231750488
Iteration 281, total loss: 1.000169038772583, discriminative loss: 7.123282432556152
Iteration 282, total loss: 1.0001124143600464, discriminative loss: 7.170283317565918
Iteration 283, total loss: 1.0001546144485474, discriminative loss: 7.111726760864258
Iteration 284, total loss: 1.0000722408294678, discriminative loss: 7.118323802947998
Iteration 285, total loss: 1.00020432472229, discriminative loss: 6.981464862823486
Iteration 286, total loss: 1.0000637769699097, discriminative loss: 7.308691501617432
Iteration 287, total loss: 1.0001335144042969, discriminative loss: 7.278262138366699
Iteration 288, total loss: 1.0001006126403809, discriminative loss: 7.179328918457031
Iteration 289, total loss: 1.0000859498977661, discriminative loss: 7.180755138397217
Iteration 290, total loss: 1.0000678300857544, discriminative loss: 7.310842514038086
Iteration 291, total loss: 1.0001060962677002, discriminative loss: 7.281382083892822
Iteration 292, total loss: 1.0001356601715088, discriminative loss: 7.200929641723633
Iteration 293, total loss: 1.0001966953277588, discriminative loss: 7.125094413757324
Iteration 294, total loss: 1.0002150535583496, discriminative loss: 7.188899993896484
Iteration 295, total loss: 1.0001226663589478, discriminative loss: 7.022063255310059
Iteration 296, total loss: 1.0001139640808105, discriminative loss: 7.01576042175293
Iteration 297, total loss: 1.0001819133758545, discriminative loss: 7.196494102478027
Iteration 298, total loss: 1.0001479387283325, discriminative loss: 7.184884071350098
Iteration 299, total loss: 1.0002257823944092, discriminative loss: 7.2356977462768555
Iteration 300, total loss: 1.0001016855239868, discriminative loss: 7.225179672241211
Iteration 301, total loss: 1.0001848936080933, discriminative loss: 7.128338813781738
Iteration 302, total loss: 1.000092625617981, discriminative loss: 7.001355171203613
Iteration 303, total loss: 1.0001304149627686, discriminative loss: 7.279287338256836
Iteration 304, total loss: 1.00009286403656, discriminative loss: 7.226543426513672
Iteration 305, total loss: 1.0002272129058838, discriminative loss: 7.32070779800415
Iteration 306, total loss: 1.0002321004867554, discriminative loss: 7.100588321685791
Iteration 307, total loss: 1.0001728534698486, discriminative loss: 7.072905540466309
Iteration 308, total loss: 1.0003095865249634, discriminative loss: 7.134467124938965
Iteration 309, total loss: 1.000239610671997, discriminative loss: 7.114785671234131
Iteration 310, total loss: 1.0000873804092407, discriminative loss: 7.120233535766602
Iteration 311, total loss: 1.0001965761184692, discriminative loss: 7.115171432495117
Iteration 312, total loss: 1.0001020431518555, discriminative loss: 7.191941261291504
Iteration 313, total loss: 1.0005145072937012, discriminative loss: 7.162764072418213
Iteration 314, total loss: 1.0001552104949951, discriminative loss: 7.086799144744873
Iteration 315, total loss: 1.0000832080841064, discriminative loss: 7.222443103790283
Iteration 316, total loss: 1.000116229057312, discriminative loss: 7.227476119995117
Iteration 317, total loss: 1.000152826309204, discriminative loss: 6.98628568649292
Iteration 318, total loss: 1.0003159046173096, discriminative loss: 7.230564117431641
Iteration 319, total loss: 1.0003559589385986, discriminative loss: 7.16362190246582
Iteration 320, total loss: 1.0000708103179932, discriminative loss: 7.273367404937744
Iteration 321, total loss: 1.0001004934310913, discriminative loss: 7.273094177246094
Iteration 322, total loss: 1.0000680685043335, discriminative loss: 7.234037399291992
Iteration 323, total loss: 1.0004185438156128, discriminative loss: 7.113311767578125
Iteration 324, total loss: 1.0000922679901123, discriminative loss: 7.053139686584473
Iteration 325, total loss: 1.0002905130386353, discriminative loss: 7.100133895874023
Iteration 326, total loss: 1.000107765197754, discriminative loss: 7.181750774383545
Iteration 327, total loss: 1.0001411437988281, discriminative loss: 7.132652759552002
Iteration 328, total loss: 1.000122308731079, discriminative loss: 7.031828880310059
Iteration 329, total loss: 1.000069499015808, discriminative loss: 7.131182670593262
Iteration 330, total loss: 1.0002731084823608, discriminative loss: 7.234811782836914
Iteration 331, total loss: 1.0000877380371094, discriminative loss: 6.9972310066223145
Iteration 332, total loss: 1.0002235174179077, discriminative loss: 7.265928268432617
Iteration 333, total loss: 1.0001106262207031, discriminative loss: 7.225695610046387
Iteration 334, total loss: 1.0001435279846191, discriminative loss: 7.0557050704956055
Iteration 335, total loss: 1.000089168548584, discriminative loss: 7.12596321105957
Iteration 336, total loss: 1.000075101852417, discriminative loss: 6.996711730957031
Iteration 337, total loss: 1.0002485513687134, discriminative loss: 7.188120365142822
Iteration 338, total loss: 1.0001018047332764, discriminative loss: 7.333685398101807
Iteration 339, total loss: 1.0000512599945068, discriminative loss: 7.123500823974609
Iteration 340, total loss: 1.0001853704452515, discriminative loss: 7.081756591796875
Iteration 341, total loss: 1.000084400177002, discriminative loss: 7.314521789550781
Iteration 342, total loss: 1.0001972913742065, discriminative loss: 7.239534378051758
Iteration 343, total loss: 1.0003618001937866, discriminative loss: 7.199979782104492
Iteration 344, total loss: 1.0000832080841064, discriminative loss: 7.23264741897583
Iteration 345, total loss: 1.000077724456787, discriminative loss: 6.9640350341796875
Iteration 346, total loss: 1.0000689029693604, discriminative loss: 7.092155456542969
Iteration 347, total loss: 1.0001376867294312, discriminative loss: 7.271812438964844
Iteration 348, total loss: 1.0002617835998535, discriminative loss: 7.06180477142334
Iteration 349, total loss: 1.0001081228256226, discriminative loss: 7.063102722167969
Iteration 350, total loss: 1.0001325607299805, discriminative loss: 7.208860397338867
Iteration 351, total loss: 1.0001698732376099, discriminative loss: 7.304536819458008
Iteration 352, total loss: 1.0001095533370972, discriminative loss: 7.136361122131348
Iteration 353, total loss: 1.0002074241638184, discriminative loss: 7.241344451904297
Iteration 354, total loss: 1.0001147985458374, discriminative loss: 7.016455173492432
Iteration 355, total loss: 1.0000799894332886, discriminative loss: 7.1003241539001465
Iteration 356, total loss: 1.0001094341278076, discriminative loss: 7.104275703430176
Iteration 357, total loss: 1.0002837181091309, discriminative loss: 7.216228485107422
Iteration 358, total loss: 1.0000476837158203, discriminative loss: 7.301288604736328
Iteration 359, total loss: 1.0002281665802002, discriminative loss: 7.077893257141113
Iteration 360, total loss: 1.0000628232955933, discriminative loss: 7.085053443908691
Iteration 361, total loss: 1.000084638595581, discriminative loss: 7.257097244262695
Iteration 362, total loss: 1.0000923871994019, discriminative loss: 7.236469268798828
Iteration 363, total loss: 1.0000861883163452, discriminative loss: 7.016082763671875
Iteration 364, total loss: 1.0001462697982788, discriminative loss: 7.083202362060547
Iteration 365, total loss: 1.0000747442245483, discriminative loss: 7.237639904022217
Iteration 366, total loss: 1.0000683069229126, discriminative loss: 7.086711883544922
Iteration 367, total loss: 1.0000357627868652, discriminative loss: 7.118074893951416
Iteration 368, total loss: 1.000062346458435, discriminative loss: 7.080573558807373
Iteration 369, total loss: 1.0000499486923218, discriminative loss: 7.120281219482422
Iteration 370, total loss: 1.0001047849655151, discriminative loss: 7.317108631134033
Iteration 371, total loss: 1.0000578165054321, discriminative loss: 7.251567840576172
Iteration 372, total loss: 1.000101089477539, discriminative loss: 7.25100040435791
Iteration 373, total loss: 1.000178575515747, discriminative loss: 7.235156536102295
Iteration 374, total loss: 1.0001015663146973, discriminative loss: 7.102015495300293
Iteration 375, total loss: 1.0002281665802002, discriminative loss: 7.18673849105835
Iteration 376, total loss: 1.000119924545288, discriminative loss: 7.271049499511719
Iteration 377, total loss: 1.0001014471054077, discriminative loss: 7.218165874481201
Iteration 378, total loss: 1.000028133392334, discriminative loss: 7.069610118865967
Iteration 379, total loss: 1.0001630783081055, discriminative loss: 7.200916767120361
Iteration 380, total loss: 1.0000888109207153, discriminative loss: 7.237361907958984
Iteration 381, total loss: 1.0000519752502441, discriminative loss: 7.15419864654541
Iteration 382, total loss: 1.0000789165496826, discriminative loss: 7.116293430328369
Iteration 383, total loss: 1.0003479719161987, discriminative loss: 7.019445419311523
Iteration 384, total loss: 1.0000401735305786, discriminative loss: 7.258398056030273
Iteration 385, total loss: 1.0000755786895752, discriminative loss: 7.140542984008789
Iteration 386, total loss: 1.0000826120376587, discriminative loss: 7.300168037414551
Iteration 387, total loss: 1.000035047531128, discriminative loss: 7.076634407043457
Iteration 388, total loss: 1.0000313520431519, discriminative loss: 7.183508396148682
Iteration 389, total loss: 1.000089406967163, discriminative loss: 6.989235877990723
Iteration 390, total loss: 1.000115156173706, discriminative loss: 7.128472328186035
Iteration 391, total loss: 1.0001782178878784, discriminative loss: 7.283559322357178
Iteration 392, total loss: 1.0001033544540405, discriminative loss: 7.129797458648682
Iteration 393, total loss: 1.0001118183135986, discriminative loss: 7.155137062072754
Iteration 394, total loss: 1.0000683069229126, discriminative loss: 7.1265363693237305
Iteration 395, total loss: 1.0000585317611694, discriminative loss: 7.256812572479248
Iteration 396, total loss: 1.0000656843185425, discriminative loss: 7.225737571716309
Iteration 397, total loss: 1.0001784563064575, discriminative loss: 6.961907863616943
Iteration 398, total loss: 1.0000765323638916, discriminative loss: 6.935567855834961
Iteration 399, total loss: 1.0000555515289307, discriminative loss: 7.272390842437744
Iteration 400, total loss: 1.0000723600387573, discriminative loss: 7.140641212463379
Iteration 401, total loss: 1.0000393390655518, discriminative loss: 7.144191741943359
Iteration 402, total loss: 1.0000419616699219, discriminative loss: 7.219151496887207
Iteration 403, total loss: 1.0000438690185547, discriminative loss: 7.149445533752441
Iteration 404, total loss: 1.0001035928726196, discriminative loss: 7.092398643493652
Iteration 405, total loss: 1.0000684261322021, discriminative loss: 7.209244251251221
Iteration 406, total loss: 1.0001014471054077, discriminative loss: 6.938913822174072
Iteration 407, total loss: 1.0000693798065186, discriminative loss: 7.281399726867676
Iteration 408, total loss: 1.0000869035720825, discriminative loss: 6.983077049255371
Iteration 409, total loss: 1.0000667572021484, discriminative loss: 7.2661566734313965
Iteration 410, total loss: 1.0004041194915771, discriminative loss: 7.085516452789307
Iteration 411, total loss: 1.000099539756775, discriminative loss: 7.15162467956543
Iteration 412, total loss: 1.0000745058059692, discriminative loss: 7.163941383361816
Iteration 413, total loss: 1.0001521110534668, discriminative loss: 7.051085948944092
Iteration 414, total loss: 1.0001778602600098, discriminative loss: 7.263686180114746
Iteration 415, total loss: 1.0001757144927979, discriminative loss: 7.156604290008545
Iteration 416, total loss: 1.0001378059387207, discriminative loss: 7.024566650390625
Iteration 417, total loss: 1.0000873804092407, discriminative loss: 6.9846649169921875
Iteration 418, total loss: 1.0000715255737305, discriminative loss: 7.138559341430664
Iteration 419, total loss: 1.000223159790039, discriminative loss: 7.3371195793151855
Iteration 420, total loss: 1.0000838041305542, discriminative loss: 7.2604546546936035
Iteration 421, total loss: 1.0002349615097046, discriminative loss: 7.162822246551514
Iteration 422, total loss: 1.0005334615707397, discriminative loss: 7.25438117980957
Iteration 423, total loss: 1.0000396966934204, discriminative loss: 7.092511177062988
Iteration 424, total loss: 1.000124216079712, discriminative loss: 7.165270805358887
Iteration 425, total loss: 1.0000545978546143, discriminative loss: 7.157064437866211
Iteration 426, total loss: 1.0001130104064941, discriminative loss: 7.135864734649658
Iteration 427, total loss: 1.0000253915786743, discriminative loss: 7.2295684814453125
Iteration 428, total loss: 1.0003308057785034, discriminative loss: 7.013690948486328
Iteration 429, total loss: 1.0001903772354126, discriminative loss: 7.28074836730957
Iteration 430, total loss: 1.0000989437103271, discriminative loss: 6.998861312866211
Iteration 431, total loss: 1.0000826120376587, discriminative loss: 7.061416149139404
Iteration 432, total loss: 1.0005780458450317, discriminative loss: 7.115490436553955
Iteration 433, total loss: 1.0002919435501099, discriminative loss: 7.186596870422363
Iteration 434, total loss: 1.0000762939453125, discriminative loss: 7.1643500328063965
Iteration 435, total loss: 1.000065803527832, discriminative loss: 7.176202774047852
Iteration 436, total loss: 1.0000566244125366, discriminative loss: 7.19461727142334
Iteration 437, total loss: 1.000337839126587, discriminative loss: 7.26207160949707
Iteration 438, total loss: 1.0001014471054077, discriminative loss: 7.0913872718811035
Iteration 439, total loss: 1.0000954866409302, discriminative loss: 7.176401138305664
Iteration 440, total loss: 1.0002878904342651, discriminative loss: 7.142316818237305
Iteration 441, total loss: 1.0003424882888794, discriminative loss: 7.186108589172363
Iteration 442, total loss: 1.0000765323638916, discriminative loss: 7.232570648193359
Iteration 443, total loss: 1.0000988245010376, discriminative loss: 7.097283363342285
Iteration 444, total loss: 1.0000629425048828, discriminative loss: 7.34189510345459
Iteration 445, total loss: 1.0000874996185303, discriminative loss: 7.1969499588012695
Iteration 446, total loss: 1.000141978263855, discriminative loss: 7.057980537414551
Iteration 447, total loss: 1.0001220703125, discriminative loss: 7.0883026123046875
Iteration 448, total loss: 1.0001393556594849, discriminative loss: 7.160161972045898
Iteration 449, total loss: 1.0002840757369995, discriminative loss: 7.071156024932861
Iteration 450, total loss: 1.0002628564834595, discriminative loss: 7.183346271514893
Iteration 451, total loss: 1.0000832080841064, discriminative loss: 7.224489688873291
Iteration 452, total loss: 1.0000803470611572, discriminative loss: 7.058966636657715
Iteration 453, total loss: 1.000160813331604, discriminative loss: 7.14341926574707
Iteration 454, total loss: 1.000083088874817, discriminative loss: 7.154745578765869
Iteration 455, total loss: 1.000032901763916, discriminative loss: 7.234803199768066
Iteration 456, total loss: 1.0000545978546143, discriminative loss: 7.160966873168945
Iteration 457, total loss: 1.0002764463424683, discriminative loss: 6.884316444396973
Iteration 458, total loss: 1.0002317428588867, discriminative loss: 7.147850036621094
Iteration 459, total loss: 1.0002477169036865, discriminative loss: 7.166657447814941
Iteration 460, total loss: 1.000046968460083, discriminative loss: 7.173798561096191
Iteration 461, total loss: 1.0000696182250977, discriminative loss: 7.008608818054199
Iteration 462, total loss: 1.0001078844070435, discriminative loss: 7.285277366638184
Iteration 463, total loss: 1.0001095533370972, discriminative loss: 6.955465793609619
Iteration 464, total loss: 1.0000325441360474, discriminative loss: 7.305980682373047
Iteration 465, total loss: 1.0001556873321533, discriminative loss: 7.2117719650268555
Iteration 466, total loss: 1.0001325607299805, discriminative loss: 7.141369342803955
Iteration 467, total loss: 1.0000724792480469, discriminative loss: 7.279271125793457
Iteration 468, total loss: 1.0001132488250732, discriminative loss: 7.076320171356201
Iteration 469, total loss: 1.0000265836715698, discriminative loss: 7.085979461669922
Iteration 470, total loss: 1.0000773668289185, discriminative loss: 7.317192077636719
Iteration 471, total loss: 1.0007621049880981, discriminative loss: 7.323185443878174
Iteration 472, total loss: 1.000032663345337, discriminative loss: 7.061596870422363
Iteration 473, total loss: 1.0001220703125, discriminative loss: 6.9667863845825195
Iteration 474, total loss: 1.0001068115234375, discriminative loss: 7.258554935455322
Iteration 475, total loss: 1.0000648498535156, discriminative loss: 7.139313697814941
Iteration 476, total loss: 1.000036358833313, discriminative loss: 7.040401458740234
Iteration 477, total loss: 1.0000780820846558, discriminative loss: 6.950710773468018
Iteration 478, total loss: 1.0001096725463867, discriminative loss: 7.360227584838867
Iteration 479, total loss: 1.0000665187835693, discriminative loss: 7.345170497894287
Iteration 480, total loss: 1.0001635551452637, discriminative loss: 7.139290809631348
Iteration 481, total loss: 1.0000451803207397, discriminative loss: 7.277344703674316
Iteration 482, total loss: 1.0000447034835815, discriminative loss: 7.122491359710693
Iteration 483, total loss: 1.0000314712524414, discriminative loss: 7.1292724609375
Iteration 484, total loss: 1.000125527381897, discriminative loss: 7.116078853607178
Iteration 485, total loss: 1.0000386238098145, discriminative loss: 7.129721641540527
Iteration 486, total loss: 1.000022530555725, discriminative loss: 7.275071144104004
Iteration 487, total loss: 1.0000661611557007, discriminative loss: 7.188486576080322
Iteration 488, total loss: 1.0001298189163208, discriminative loss: 7.177559852600098
Iteration 489, total loss: 1.000077486038208, discriminative loss: 7.008959770202637
Iteration 490, total loss: 1.0002241134643555, discriminative loss: 7.092223167419434
Iteration 491, total loss: 1.0000736713409424, discriminative loss: 7.354436874389648
Iteration 492, total loss: 1.000065803527832, discriminative loss: 7.142602443695068
Iteration 493, total loss: 1.000095009803772, discriminative loss: 7.130979537963867
Iteration 494, total loss: 1.0001336336135864, discriminative loss: 6.971475601196289
Iteration 495, total loss: 1.0001695156097412, discriminative loss: 7.048745155334473
Iteration 496, total loss: 1.0002388954162598, discriminative loss: 7.201972007751465
Iteration 497, total loss: 1.0000532865524292, discriminative loss: 7.233447074890137
Iteration 498, total loss: 1.0000371932983398, discriminative loss: 7.221434593200684
Iteration 499, total loss: 1.0000238418579102, discriminative loss: 7.285427093505859
Iteration 500, total loss: 1.0000337362289429, discriminative loss: 7.107626914978027
Iteration 501, total loss: 1.0000896453857422, discriminative loss: 7.3126606941223145
Iteration 502, total loss: 1.0000816583633423, discriminative loss: 7.207155704498291
Iteration 503, total loss: 1.000274419784546, discriminative loss: 7.285810470581055
Iteration 504, total loss: 1.000044822692871, discriminative loss: 7.004205703735352
Iteration 505, total loss: 1.0002609491348267, discriminative loss: 7.326682090759277
Iteration 506, total loss: 1.0002317428588867, discriminative loss: 7.158353805541992
Iteration 507, total loss: 1.0000437498092651, discriminative loss: 7.0014801025390625
Iteration 508, total loss: 1.0000680685043335, discriminative loss: 7.093343734741211
Iteration 509, total loss: 1.0000611543655396, discriminative loss: 7.317392349243164
Iteration 510, total loss: 1.0001181364059448, discriminative loss: 7.120142459869385
Iteration 511, total loss: 1.0000989437103271, discriminative loss: 7.219390869140625
Iteration 512, total loss: 1.0000711679458618, discriminative loss: 7.175612926483154
Iteration 513, total loss: 1.0000771284103394, discriminative loss: 7.186589241027832
Iteration 514, total loss: 1.0000182390213013, discriminative loss: 7.271178245544434
Iteration 515, total loss: 1.0001065731048584, discriminative loss: 7.149190902709961
Iteration 516, total loss: 1.0000371932983398, discriminative loss: 7.032481670379639
Iteration 517, total loss: 1.0001423358917236, discriminative loss: 7.209450721740723
Iteration 518, total loss: 1.0000382661819458, discriminative loss: 7.254182815551758
Iteration 519, total loss: 1.0000568628311157, discriminative loss: 7.259904861450195
Iteration 520, total loss: 1.0001420974731445, discriminative loss: 7.27729606628418
Iteration 521, total loss: 1.0000436305999756, discriminative loss: 6.989628314971924
Iteration 522, total loss: 1.0000473260879517, discriminative loss: 7.167059421539307
Iteration 523, total loss: 1.0000367164611816, discriminative loss: 7.199822425842285
Iteration 524, total loss: 1.0000380277633667, discriminative loss: 7.056290626525879
Iteration 525, total loss: 1.000040054321289, discriminative loss: 7.300451278686523
Iteration 526, total loss: 1.0000334978103638, discriminative loss: 7.100065231323242
Iteration 527, total loss: 1.000018835067749, discriminative loss: 7.037894248962402
Iteration 528, total loss: 1.00003182888031, discriminative loss: 7.1102495193481445
Iteration 529, total loss: 1.0001306533813477, discriminative loss: 7.129985332489014
Iteration 530, total loss: 1.0000360012054443, discriminative loss: 7.153034210205078
Iteration 531, total loss: 1.0001810789108276, discriminative loss: 7.209841728210449
Iteration 532, total loss: 1.0001249313354492, discriminative loss: 7.156988620758057
Iteration 533, total loss: 1.000147819519043, discriminative loss: 7.2662248611450195
Iteration 534, total loss: 1.000068187713623, discriminative loss: 7.224832534790039
Iteration 535, total loss: 1.0001477003097534, discriminative loss: 7.075911521911621
Iteration 536, total loss: 1.0000905990600586, discriminative loss: 6.998567581176758
Iteration 537, total loss: 1.0000829696655273, discriminative loss: 7.266782760620117
Iteration 538, total loss: 1.0000298023223877, discriminative loss: 7.085389614105225
Iteration 539, total loss: 1.0000287294387817, discriminative loss: 7.260499954223633
Iteration 540, total loss: 1.0001699924468994, discriminative loss: 7.084442138671875
Iteration 541, total loss: 1.0001225471496582, discriminative loss: 7.190518379211426
Iteration 542, total loss: 1.0000382661819458, discriminative loss: 7.1305646896362305
Iteration 543, total loss: 1.0000927448272705, discriminative loss: 7.039548873901367
Iteration 544, total loss: 1.0000765323638916, discriminative loss: 7.229885101318359
Iteration 545, total loss: 1.0001189708709717, discriminative loss: 7.1696457862854
Iteration 546, total loss: 1.000023603439331, discriminative loss: 7.217952251434326
Iteration 547, total loss: 1.0002142190933228, discriminative loss: 7.238597393035889
Iteration 548, total loss: 1.0000708103179932, discriminative loss: 7.064168453216553
Iteration 549, total loss: 1.0000324249267578, discriminative loss: 7.023858070373535
Iteration 550, total loss: 1.0001767873764038, discriminative loss: 7.116772651672363
Iteration 551, total loss: 1.000058889389038, discriminative loss: 7.1518874168396
Iteration 552, total loss: 1.000067114830017, discriminative loss: 7.247191429138184
Iteration 553, total loss: 1.0000425577163696, discriminative loss: 7.159396648406982
Iteration 554, total loss: 1.0000554323196411, discriminative loss: 7.126735687255859
Iteration 555, total loss: 1.0000510215759277, discriminative loss: 7.1618266105651855
Iteration 556, total loss: 1.0000524520874023, discriminative loss: 7.001269340515137
Iteration 557, total loss: 1.0000296831130981, discriminative loss: 7.14206600189209
Iteration 558, total loss: 1.0000296831130981, discriminative loss: 7.204133033752441
Iteration 559, total loss: 1.0000678300857544, discriminative loss: 7.204590797424316
Iteration 560, total loss: 1.0001168251037598, discriminative loss: 7.153260707855225
Iteration 561, total loss: 1.000036597251892, discriminative loss: 7.176846981048584
Iteration 562, total loss: 1.0000391006469727, discriminative loss: 7.302114486694336
Iteration 563, total loss: 1.0002394914627075, discriminative loss: 7.244475364685059
Iteration 564, total loss: 1.0000272989273071, discriminative loss: 7.186604976654053
Iteration 565, total loss: 1.0000929832458496, discriminative loss: 6.945850372314453
Iteration 566, total loss: 1.0001561641693115, discriminative loss: 7.101984977722168
Iteration 567, total loss: 1.0000823736190796, discriminative loss: 7.213711738586426
Iteration 568, total loss: 1.0000580549240112, discriminative loss: 7.10982608795166
Iteration 569, total loss: 1.0002214908599854, discriminative loss: 7.224274635314941
Iteration 570, total loss: 1.0000520944595337, discriminative loss: 7.308710098266602
Iteration 571, total loss: 1.0000914335250854, discriminative loss: 7.150904655456543
Iteration 572, total loss: 1.000268816947937, discriminative loss: 6.962402820587158
Iteration 573, total loss: 1.000044345855713, discriminative loss: 7.275705814361572
Iteration 574, total loss: 1.0001592636108398, discriminative loss: 7.202340602874756
Iteration 575, total loss: 1.0000429153442383, discriminative loss: 7.251091957092285
Iteration 576, total loss: 1.0001507997512817, discriminative loss: 7.113152503967285
Iteration 577, total loss: 1.000063419342041, discriminative loss: 7.062695503234863
Iteration 578, total loss: 1.0000190734863281, discriminative loss: 7.086264133453369
Iteration 579, total loss: 1.000035047531128, discriminative loss: 7.115252494812012
Iteration 580, total loss: 1.0000860691070557, discriminative loss: 7.3175482749938965
Iteration 581, total loss: 1.0001827478408813, discriminative loss: 7.210269927978516
Iteration 582, total loss: 1.0000569820404053, discriminative loss: 7.001234531402588
Iteration 583, total loss: 1.0000331401824951, discriminative loss: 7.14258337020874
Iteration 584, total loss: 1.0000455379486084, discriminative loss: 7.283755302429199
Iteration 585, total loss: 1.0003551244735718, discriminative loss: 7.192996978759766
Iteration 586, total loss: 1.0003165006637573, discriminative loss: 7.130120277404785
Iteration 587, total loss: 1.0000598430633545, discriminative loss: 7.151387691497803
Iteration 588, total loss: 1.0001438856124878, discriminative loss: 7.0993332862854
Iteration 589, total loss: 1.0000741481781006, discriminative loss: 7.161585330963135
Iteration 590, total loss: 1.0000146627426147, discriminative loss: 7.325013637542725
Iteration 591, total loss: 1.0000091791152954, discriminative loss: 7.115262508392334
Iteration 592, total loss: 1.0003151893615723, discriminative loss: 7.16417932510376
Iteration 593, total loss: 1.0000245571136475, discriminative loss: 7.129380226135254
Iteration 594, total loss: 1.0001052618026733, discriminative loss: 7.227386474609375
Iteration 595, total loss: 1.0000543594360352, discriminative loss: 7.250931262969971
Iteration 596, total loss: 1.000186800956726, discriminative loss: 7.156159400939941
Iteration 597, total loss: 1.0000478029251099, discriminative loss: 7.08094596862793
Iteration 598, total loss: 1.0000358819961548, discriminative loss: 7.128530502319336
Iteration 599, total loss: 1.0000345706939697, discriminative loss: 7.142546653747559
Iteration 600, total loss: 1.0000224113464355, discriminative loss: 7.215360641479492
Iteration 601, total loss: 1.0001788139343262, discriminative loss: 7.203804969787598
Iteration 602, total loss: 1.0001418590545654, discriminative loss: 7.188663005828857
Iteration 603, total loss: 1.000346064567566, discriminative loss: 7.191908836364746
Iteration 604, total loss: 1.0002368688583374, discriminative loss: 7.281759262084961
Iteration 605, total loss: 1.0000801086425781, discriminative loss: 7.199208736419678
Iteration 606, total loss: 1.0000990629196167, discriminative loss: 7.081002235412598
Iteration 607, total loss: 1.00003182888031, discriminative loss: 7.156288146972656
Iteration 608, total loss: 1.0000413656234741, discriminative loss: 7.362130165100098
Iteration 609, total loss: 1.0000855922698975, discriminative loss: 7.119880199432373
Iteration 610, total loss: 1.0000523328781128, discriminative loss: 7.092508792877197
Iteration 611, total loss: 1.000085711479187, discriminative loss: 7.0804057121276855
Iteration 612, total loss: 1.0000489950180054, discriminative loss: 7.237556457519531
Iteration 613, total loss: 1.0001424551010132, discriminative loss: 7.065883636474609
Iteration 614, total loss: 1.0000474452972412, discriminative loss: 7.171950340270996
Iteration 615, total loss: 1.0000733137130737, discriminative loss: 7.229413032531738
Iteration 616, total loss: 1.0001318454742432, discriminative loss: 7.187142372131348
Iteration 617, total loss: 1.000040054321289, discriminative loss: 7.1838226318359375
Iteration 618, total loss: 1.0000306367874146, discriminative loss: 7.227049350738525
Iteration 619, total loss: 1.0000324249267578, discriminative loss: 7.122072219848633
Iteration 620, total loss: 1.0000184774398804, discriminative loss: 7.019012928009033
Iteration 621, total loss: 1.0000147819519043, discriminative loss: 7.039426803588867
Iteration 622, total loss: 1.0000582933425903, discriminative loss: 7.153040885925293
Iteration 623, total loss: 1.0001420974731445, discriminative loss: 7.188529014587402
Iteration 624, total loss: 1.000098466873169, discriminative loss: 7.115039348602295
Iteration 625, total loss: 1.0000171661376953, discriminative loss: 7.222195625305176
Iteration 626, total loss: 1.0001243352890015, discriminative loss: 7.144962310791016
Iteration 627, total loss: 1.0001118183135986, discriminative loss: 7.183777809143066
Iteration 628, total loss: 1.0000261068344116, discriminative loss: 7.131310939788818
Iteration 629, total loss: 1.0000479221343994, discriminative loss: 7.175474643707275
Iteration 630, total loss: 1.0000190734863281, discriminative loss: 7.192192077636719
Iteration 631, total loss: 1.000096082687378, discriminative loss: 7.119921684265137
Iteration 632, total loss: 1.000035047531128, discriminative loss: 7.106307506561279
Iteration 633, total loss: 1.0002491474151611, discriminative loss: 7.223029136657715
Iteration 634, total loss: 1.0002449750900269, discriminative loss: 7.124654769897461
Iteration 635, total loss: 1.0000228881835938, discriminative loss: 7.054288864135742
Iteration 636, total loss: 1.0004644393920898, discriminative loss: 7.281370639801025
Iteration 637, total loss: 1.0000340938568115, discriminative loss: 7.002864360809326
Iteration 638, total loss: 1.0000799894332886, discriminative loss: 7.1553144454956055
Iteration 639, total loss: 1.000099778175354, discriminative loss: 7.1288018226623535
Iteration 640, total loss: 1.000067949295044, discriminative loss: 7.073590278625488
Iteration 641, total loss: 1.0000380277633667, discriminative loss: 7.17396354675293
Iteration 642, total loss: 1.000049114227295, discriminative loss: 7.238579750061035
Iteration 643, total loss: 1.0000358819961548, discriminative loss: 7.169206619262695
Iteration 644, total loss: 1.0000513792037964, discriminative loss: 7.166910171508789
Iteration 645, total loss: 1.0000580549240112, discriminative loss: 7.131974220275879
Iteration 646, total loss: 1.000144600868225, discriminative loss: 7.10022497177124
Iteration 647, total loss: 1.0000123977661133, discriminative loss: 7.21904993057251
Iteration 648, total loss: 1.0000205039978027, discriminative loss: 7.094186782836914
Iteration 649, total loss: 1.0002162456512451, discriminative loss: 7.136520862579346
Iteration 650, total loss: 1.0000375509262085, discriminative loss: 7.255224227905273
Iteration 651, total loss: 1.0001482963562012, discriminative loss: 7.016269683837891
Iteration 652, total loss: 1.0000163316726685, discriminative loss: 7.120134353637695
Iteration 653, total loss: 1.0000638961791992, discriminative loss: 7.097967147827148
Iteration 654, total loss: 1.0000640153884888, discriminative loss: 7.108913421630859
Iteration 655, total loss: 1.0000485181808472, discriminative loss: 7.222620487213135
Iteration 656, total loss: 1.0000181198120117, discriminative loss: 7.161129951477051
Iteration 657, total loss: 1.0000202655792236, discriminative loss: 7.150446891784668
Iteration 658, total loss: 1.0000277757644653, discriminative loss: 7.120742321014404
Iteration 659, total loss: 1.0000728368759155, discriminative loss: 7.083443641662598
Iteration 660, total loss: 1.0000619888305664, discriminative loss: 7.2420501708984375
Iteration 661, total loss: 1.000038981437683, discriminative loss: 7.089824199676514
Iteration 662, total loss: 1.0000331401824951, discriminative loss: 7.24622917175293
Iteration 663, total loss: 1.000099778175354, discriminative loss: 7.124821662902832
Training completed
Model saved to file: /home/im-zbox2/harpreet/github/anomaly-svm-study/deep_one_class_features/results/trained_model.h5
