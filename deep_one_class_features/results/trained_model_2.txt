Using SGD, 64 batch size, 2 epochs, with images normalized
Trained only on compactness loss


Using TensorFlow backend.
Reference model built
Secondary model built
Total number of iterations: 664
Iteration 0, total loss: 0.0830497220158577, discriminative loss: 8.111093521118164
Iteration 1, total loss: 0.06700926274061203, discriminative loss: 7.894895553588867
Iteration 2, total loss: 0.054796092212200165, discriminative loss: 7.516974449157715
Iteration 3, total loss: 0.04632802680134773, discriminative loss: 7.548706531524658
Iteration 4, total loss: 0.04007478803396225, discriminative loss: 8.048232078552246
Iteration 5, total loss: 0.03586404025554657, discriminative loss: 7.906126499176025
Iteration 6, total loss: 0.03067183867096901, discriminative loss: 7.899701118469238
Iteration 7, total loss: 0.025354599580168724, discriminative loss: 7.736924171447754
Iteration 8, total loss: 0.023614324629306793, discriminative loss: 7.617624282836914
Iteration 9, total loss: 0.01924380473792553, discriminative loss: 7.343069076538086
Iteration 10, total loss: 0.014300895854830742, discriminative loss: 7.89862060546875
Iteration 11, total loss: 0.015527508221566677, discriminative loss: 7.570673942565918
Iteration 12, total loss: 0.013138473965227604, discriminative loss: 7.6914143562316895
Iteration 13, total loss: 0.012181814759969711, discriminative loss: 7.719691753387451
Iteration 14, total loss: 0.010938703082501888, discriminative loss: 7.745357990264893
Iteration 15, total loss: 0.01105252280831337, discriminative loss: 7.537734031677246
Iteration 16, total loss: 0.008831627666950226, discriminative loss: 7.5042595863342285
Iteration 17, total loss: 0.009440500289201736, discriminative loss: 7.802116394042969
Iteration 18, total loss: 0.007545124739408493, discriminative loss: 7.321817398071289
Iteration 19, total loss: 0.007350455038249493, discriminative loss: 7.687936305999756
Iteration 20, total loss: 0.006151934619992971, discriminative loss: 7.46852970123291
Iteration 21, total loss: 0.006616772152483463, discriminative loss: 7.642501354217529
Iteration 22, total loss: 0.006452865432947874, discriminative loss: 7.770692348480225
Iteration 23, total loss: 0.005585715640336275, discriminative loss: 7.561142921447754
Iteration 24, total loss: 0.005587182939052582, discriminative loss: 7.409521102905273
Iteration 25, total loss: 0.004659651312977076, discriminative loss: 7.4614739418029785
Iteration 26, total loss: 0.004590825643390417, discriminative loss: 7.5253071784973145
Iteration 27, total loss: 0.004925529472529888, discriminative loss: 7.2549238204956055
Iteration 28, total loss: 0.0037971055135130882, discriminative loss: 7.637150764465332
Iteration 29, total loss: 0.00407487154006958, discriminative loss: 7.379938125610352
Iteration 30, total loss: 0.003949903883039951, discriminative loss: 7.4330010414123535
Iteration 31, total loss: 0.0036844522692263126, discriminative loss: 7.600275993347168
Iteration 32, total loss: 0.00357287866063416, discriminative loss: 7.732800483703613
Iteration 33, total loss: 0.003410948906093836, discriminative loss: 7.354671478271484
Iteration 34, total loss: 0.0036883768625557423, discriminative loss: 7.580312728881836
Iteration 35, total loss: 0.003588915104046464, discriminative loss: 7.377523899078369
Iteration 36, total loss: 0.003307571867480874, discriminative loss: 7.642154216766357
Iteration 37, total loss: 0.00303947483189404, discriminative loss: 7.497409343719482
Iteration 38, total loss: 0.0033041825518012047, discriminative loss: 7.4580817222595215
Iteration 39, total loss: 0.0028544042725116014, discriminative loss: 7.369684219360352
Iteration 40, total loss: 0.0032440454233437777, discriminative loss: 7.674877166748047
Iteration 41, total loss: 0.00235338625498116, discriminative loss: 7.563539505004883
Iteration 42, total loss: 0.0024337132927030325, discriminative loss: 7.393368244171143
Iteration 43, total loss: 0.0027419901452958584, discriminative loss: 7.585285663604736
Iteration 44, total loss: 0.002176858251914382, discriminative loss: 7.590438365936279
Iteration 45, total loss: 0.0024016788229346275, discriminative loss: 7.605081558227539
Iteration 46, total loss: 0.002570753451436758, discriminative loss: 7.320529937744141
Iteration 47, total loss: 0.0019333632662892342, discriminative loss: 7.537588596343994
Iteration 48, total loss: 0.002248602919280529, discriminative loss: 7.522435665130615
Iteration 49, total loss: 0.001963371643796563, discriminative loss: 7.503243446350098
Iteration 50, total loss: 0.002244943054392934, discriminative loss: 7.382047653198242
Iteration 51, total loss: 0.0018239312339574099, discriminative loss: 7.485723495483398
Iteration 52, total loss: 0.0017980844713747501, discriminative loss: 7.523648262023926
Iteration 53, total loss: 0.0017874700715765357, discriminative loss: 7.273529529571533
Iteration 54, total loss: 0.001635318505577743, discriminative loss: 7.490711212158203
Iteration 55, total loss: 0.002027820097282529, discriminative loss: 7.506162643432617
Iteration 56, total loss: 0.001676007523201406, discriminative loss: 7.554599761962891
Iteration 57, total loss: 0.0016808555228635669, discriminative loss: 7.39926815032959
Iteration 58, total loss: 0.0014449601294472814, discriminative loss: 7.503547191619873
Iteration 59, total loss: 0.0016106372931972146, discriminative loss: 7.3748321533203125
Iteration 60, total loss: 0.0016228352906182408, discriminative loss: 7.394375801086426
Iteration 61, total loss: 0.001459422754123807, discriminative loss: 7.084572792053223
Iteration 62, total loss: 0.0017174971289932728, discriminative loss: 7.355763912200928
Iteration 63, total loss: 0.0012162781786173582, discriminative loss: 7.350569725036621
Iteration 64, total loss: 0.0019474336877465248, discriminative loss: 7.522095680236816
Iteration 65, total loss: 0.0017902320250868797, discriminative loss: 7.494695663452148
Iteration 66, total loss: 0.0013939429773017764, discriminative loss: 7.365478038787842
Iteration 67, total loss: 0.0014885903801769018, discriminative loss: 7.55411434173584
Iteration 68, total loss: 0.0010530188446864486, discriminative loss: 7.492384433746338
Iteration 69, total loss: 0.0014183216262608767, discriminative loss: 7.243720054626465
Iteration 70, total loss: 0.0011238298611715436, discriminative loss: 7.485329627990723
Iteration 71, total loss: 0.0008970568887889385, discriminative loss: 7.5642805099487305
Iteration 72, total loss: 0.0012923810863867402, discriminative loss: 7.446292877197266
Iteration 73, total loss: 0.0011095366207882762, discriminative loss: 7.302579879760742
Iteration 74, total loss: 0.0008885759161785245, discriminative loss: 7.342226028442383
Iteration 75, total loss: 0.0010326675837859511, discriminative loss: 7.44671630859375
Iteration 76, total loss: 0.0011899935780093074, discriminative loss: 7.489218235015869
Iteration 77, total loss: 0.0009085603523999453, discriminative loss: 7.438011646270752
Iteration 78, total loss: 0.0009003529557958245, discriminative loss: 7.645509719848633
Iteration 79, total loss: 0.0008668942027725279, discriminative loss: 7.468196868896484
Iteration 80, total loss: 0.0014829272404313087, discriminative loss: 7.572098731994629
Iteration 81, total loss: 0.0009287476423196495, discriminative loss: 7.510453701019287
Iteration 82, total loss: 0.0010059861233457923, discriminative loss: 7.410869121551514
Iteration 83, total loss: 0.0010044294176623225, discriminative loss: 7.285548210144043
Iteration 84, total loss: 0.000983150559477508, discriminative loss: 7.262843132019043
Iteration 85, total loss: 0.0008789798012003303, discriminative loss: 7.61610221862793
Iteration 86, total loss: 0.0008646448841318488, discriminative loss: 7.332144737243652
Iteration 87, total loss: 0.0010852859122678638, discriminative loss: 7.213461399078369
Iteration 88, total loss: 0.0007225878071039915, discriminative loss: 7.186885833740234
Iteration 89, total loss: 0.000909375783521682, discriminative loss: 7.522806644439697
Iteration 90, total loss: 0.0008568909834139049, discriminative loss: 7.532751083374023
Iteration 91, total loss: 0.0010123996762558818, discriminative loss: 7.251974105834961
Iteration 92, total loss: 0.000822518253698945, discriminative loss: 7.448591232299805
Iteration 93, total loss: 0.0009329443564638495, discriminative loss: 7.5877227783203125
Iteration 94, total loss: 0.0007037612958811224, discriminative loss: 7.5619001388549805
Iteration 95, total loss: 0.0007443667273037136, discriminative loss: 7.313732624053955
Iteration 96, total loss: 0.0007421969203278422, discriminative loss: 7.483863830566406
Iteration 97, total loss: 0.0007151711033657193, discriminative loss: 7.438216209411621
Iteration 98, total loss: 0.0007620013784617186, discriminative loss: 7.511319160461426
Iteration 99, total loss: 0.001007269835099578, discriminative loss: 7.426608562469482
Iteration 100, total loss: 0.0009902793681249022, discriminative loss: 7.338837146759033
Iteration 101, total loss: 0.000743319105822593, discriminative loss: 7.48874044418335
Iteration 102, total loss: 0.0005579528515227139, discriminative loss: 7.514771461486816
Iteration 103, total loss: 0.0006798183312639594, discriminative loss: 7.358490943908691
Iteration 104, total loss: 0.0006171647692099214, discriminative loss: 7.446293354034424
Iteration 105, total loss: 0.0006526804063469172, discriminative loss: 7.574777603149414
Iteration 106, total loss: 0.0006502554751932621, discriminative loss: 7.505834579467773
Iteration 107, total loss: 0.0006909738876856863, discriminative loss: 7.433981895446777
Iteration 108, total loss: 0.0005972341750748456, discriminative loss: 7.499839782714844
Iteration 109, total loss: 0.0005499357357621193, discriminative loss: 7.337130546569824
Iteration 110, total loss: 0.0007372695254161954, discriminative loss: 7.38731050491333
Iteration 111, total loss: 0.0005649611121043563, discriminative loss: 7.242989540100098
Iteration 112, total loss: 0.0006561429472640157, discriminative loss: 7.455504894256592
Iteration 113, total loss: 0.0005406361888162792, discriminative loss: 7.388272285461426
Iteration 114, total loss: 0.0006020711734890938, discriminative loss: 7.452492713928223
Iteration 115, total loss: 0.00044691559742204845, discriminative loss: 7.513232231140137
Iteration 116, total loss: 0.0005463747656904161, discriminative loss: 7.3865180015563965
Iteration 117, total loss: 0.0005283846985548735, discriminative loss: 7.260211944580078
Iteration 118, total loss: 0.000651890761218965, discriminative loss: 7.494634628295898
Iteration 119, total loss: 0.0006490374216809869, discriminative loss: 7.336148262023926
Iteration 120, total loss: 0.0006420401623472571, discriminative loss: 7.381219863891602
Iteration 121, total loss: 0.0005150397773832083, discriminative loss: 7.559847831726074
Iteration 122, total loss: 0.0005880490061827004, discriminative loss: 7.278209686279297
Iteration 123, total loss: 0.0004533652390819043, discriminative loss: 7.294703960418701
Iteration 124, total loss: 0.0005258708260953426, discriminative loss: 7.665763854980469
Iteration 125, total loss: 0.0006209395942278206, discriminative loss: 7.512351989746094
Iteration 126, total loss: 0.0005551085341721773, discriminative loss: 7.376776218414307
Iteration 127, total loss: 0.0005334988818503916, discriminative loss: 7.489766597747803
Iteration 128, total loss: 0.0006734277703799307, discriminative loss: 7.171442985534668
Iteration 129, total loss: 0.0005428477888926864, discriminative loss: 7.596065998077393
Iteration 130, total loss: 0.0004893997102044523, discriminative loss: 7.428249359130859
Iteration 131, total loss: 0.0005516684614121914, discriminative loss: 7.414400100708008
Iteration 132, total loss: 0.0004866741946898401, discriminative loss: 7.491445541381836
Iteration 133, total loss: 0.0005794182070530951, discriminative loss: 7.7849345207214355
Iteration 134, total loss: 0.0005145737668499351, discriminative loss: 7.401902198791504
Iteration 135, total loss: 0.0005125135066919029, discriminative loss: 7.530064105987549
Iteration 136, total loss: 0.0005841528763994575, discriminative loss: 7.451841354370117
Iteration 137, total loss: 0.000471352890599519, discriminative loss: 7.268087387084961
Iteration 138, total loss: 0.0003358367539476603, discriminative loss: 7.388434886932373
Iteration 139, total loss: 0.00041426243842579424, discriminative loss: 7.446109771728516
Iteration 140, total loss: 0.00042635484714992344, discriminative loss: 7.547952651977539
Iteration 141, total loss: 0.0004835196305066347, discriminative loss: 7.415130615234375
Iteration 142, total loss: 0.00048614534898661077, discriminative loss: 7.537165641784668
Iteration 143, total loss: 0.00035811992711387575, discriminative loss: 7.435610771179199
Iteration 144, total loss: 0.00046169289271347225, discriminative loss: 7.334553241729736
Iteration 145, total loss: 0.0004214567306917161, discriminative loss: 7.396200656890869
Iteration 146, total loss: 0.0005789475981146097, discriminative loss: 7.262075424194336
Iteration 147, total loss: 0.0003962510672863573, discriminative loss: 7.48283576965332
Iteration 148, total loss: 0.00045444403076544404, discriminative loss: 7.568227767944336
Iteration 149, total loss: 0.000461363437352702, discriminative loss: 7.35493278503418
Iteration 150, total loss: 0.00043333982466720045, discriminative loss: 7.55071496963501
Iteration 151, total loss: 0.0004734934773296118, discriminative loss: 7.357309341430664
Iteration 152, total loss: 0.0004324119654484093, discriminative loss: 7.400323390960693
Iteration 153, total loss: 0.00035130261676386, discriminative loss: 7.161647319793701
Iteration 154, total loss: 0.0005865083076059818, discriminative loss: 7.4240851402282715
Iteration 155, total loss: 0.0004905615351162851, discriminative loss: 7.319252967834473
Iteration 156, total loss: 0.00035266735358163714, discriminative loss: 7.756267547607422
Iteration 157, total loss: 0.0003320376272313297, discriminative loss: 7.2775115966796875
Iteration 158, total loss: 0.0003607272228691727, discriminative loss: 7.450733661651611
Iteration 159, total loss: 0.0004464475205168128, discriminative loss: 7.292301177978516
Iteration 160, total loss: 0.0005236473516561091, discriminative loss: 7.399072647094727
Iteration 161, total loss: 0.00035347905941307545, discriminative loss: 7.653975486755371
Iteration 162, total loss: 0.0004022463399451226, discriminative loss: 7.444306373596191
Iteration 163, total loss: 0.00040044798515737057, discriminative loss: 7.523542881011963
Iteration 164, total loss: 0.0004610132018569857, discriminative loss: 7.5916242599487305
Iteration 165, total loss: 0.0004263575829099864, discriminative loss: 7.5200653076171875
Iteration 166, total loss: 0.00038248198688961565, discriminative loss: 7.657320022583008
Iteration 167, total loss: 0.0004505531978793442, discriminative loss: 7.306800842285156
Iteration 168, total loss: 0.00043801681022159755, discriminative loss: 7.401097297668457
Iteration 169, total loss: 0.00033207205706276, discriminative loss: 7.42967414855957
Iteration 170, total loss: 0.00031333198421634734, discriminative loss: 7.594472885131836
Iteration 171, total loss: 0.00042825378477573395, discriminative loss: 7.267629623413086
Iteration 172, total loss: 0.00040414647082798183, discriminative loss: 7.288698196411133
Iteration 173, total loss: 0.00038732567918486893, discriminative loss: 7.4029412269592285
Iteration 174, total loss: 0.0003594917943701148, discriminative loss: 7.400012016296387
Iteration 175, total loss: 0.0003657961206045002, discriminative loss: 7.565669059753418
Iteration 176, total loss: 0.0003596919705159962, discriminative loss: 7.369391441345215
Iteration 177, total loss: 0.00036052369978278875, discriminative loss: 7.534694671630859
Iteration 178, total loss: 0.00037895594141446054, discriminative loss: 7.290408611297607
Iteration 179, total loss: 0.0003439142310526222, discriminative loss: 7.455527305603027
Iteration 180, total loss: 0.0003586720849853009, discriminative loss: 7.511500835418701
Iteration 181, total loss: 0.000380876095732674, discriminative loss: 7.498117923736572
Iteration 182, total loss: 0.00036082349834032357, discriminative loss: 7.2394866943359375
Iteration 183, total loss: 0.00032769341487437487, discriminative loss: 7.699057579040527
Iteration 184, total loss: 0.00038387050153687596, discriminative loss: 7.409146308898926
Iteration 185, total loss: 0.00034570155548863113, discriminative loss: 7.536059856414795
Iteration 186, total loss: 0.00041214851080439985, discriminative loss: 7.3405961990356445
Iteration 187, total loss: 0.0004042738291900605, discriminative loss: 7.32794189453125
Iteration 188, total loss: 0.0003143357753288001, discriminative loss: 7.622288703918457
Iteration 189, total loss: 0.0003561855119187385, discriminative loss: 7.392975807189941
Iteration 190, total loss: 0.00027375121135264635, discriminative loss: 7.558575630187988
Iteration 191, total loss: 0.0002957171527668834, discriminative loss: 7.203156471252441
Iteration 192, total loss: 0.00025824972544796765, discriminative loss: 7.395031929016113
Iteration 193, total loss: 0.00035712303360924125, discriminative loss: 7.3542680740356445
Iteration 194, total loss: 0.00027263411902822554, discriminative loss: 7.441476345062256
Iteration 195, total loss: 0.00036162466858513653, discriminative loss: 7.327644348144531
Iteration 196, total loss: 0.0002924271684605628, discriminative loss: 7.407222747802734
Iteration 197, total loss: 0.0003035687259398401, discriminative loss: 7.3858642578125
Iteration 198, total loss: 0.00034693768247962, discriminative loss: 7.323136806488037
Iteration 199, total loss: 0.00027538728318177164, discriminative loss: 7.363349914550781
Iteration 200, total loss: 0.0003844659950118512, discriminative loss: 7.464491844177246
Iteration 201, total loss: 0.0002964068844448775, discriminative loss: 7.28607702255249
Iteration 202, total loss: 0.0003492594987619668, discriminative loss: 7.264267444610596
Iteration 203, total loss: 0.000379824370611459, discriminative loss: 7.329298973083496
Iteration 204, total loss: 0.0003499518206808716, discriminative loss: 7.3096923828125
Iteration 205, total loss: 0.0003475891426205635, discriminative loss: 7.3536176681518555
Iteration 206, total loss: 0.00038625067099928856, discriminative loss: 7.3757829666137695
Iteration 207, total loss: 0.00040802996954880655, discriminative loss: 7.329047679901123
Iteration 208, total loss: 0.0003031320811714977, discriminative loss: 7.435031890869141
Iteration 209, total loss: 0.00026618820265866816, discriminative loss: 7.4364848136901855
Iteration 210, total loss: 0.0002541295252740383, discriminative loss: 7.359102249145508
Iteration 211, total loss: 0.00026499293744564056, discriminative loss: 7.420094966888428
Iteration 212, total loss: 0.0003609240520745516, discriminative loss: 7.552346706390381
Iteration 213, total loss: 0.0002678594028111547, discriminative loss: 7.251526355743408
Iteration 214, total loss: 0.0002880393876694143, discriminative loss: 7.666196823120117
Iteration 215, total loss: 0.00030209950637072325, discriminative loss: 7.1845879554748535
Iteration 216, total loss: 0.00023482427059207112, discriminative loss: 7.313318252563477
Iteration 217, total loss: 0.00028150479192845523, discriminative loss: 7.4354567527771
Iteration 218, total loss: 0.0004187312151771039, discriminative loss: 7.327337265014648
Iteration 219, total loss: 0.0003140284970868379, discriminative loss: 7.392345905303955
Iteration 220, total loss: 0.00033075560349971056, discriminative loss: 7.292113304138184
Iteration 221, total loss: 0.00028164073592051864, discriminative loss: 7.493168354034424
Iteration 222, total loss: 0.00025213256594724953, discriminative loss: 7.528250694274902
Iteration 223, total loss: 0.0003441275330260396, discriminative loss: 7.145002365112305
Iteration 224, total loss: 0.000273586978437379, discriminative loss: 7.415988922119141
Iteration 225, total loss: 0.0002670960675459355, discriminative loss: 7.361260414123535
Iteration 226, total loss: 0.0002763821103144437, discriminative loss: 7.517440319061279
Iteration 227, total loss: 0.0003003301681019366, discriminative loss: 7.557249546051025
Iteration 228, total loss: 0.00024359076633118093, discriminative loss: 7.570884704589844
Iteration 229, total loss: 0.0003355708031449467, discriminative loss: 7.31883430480957
Iteration 230, total loss: 0.00024492989177815616, discriminative loss: 7.697026252746582
Iteration 231, total loss: 0.0002592083183117211, discriminative loss: 7.472894191741943
Iteration 232, total loss: 0.0002405444683972746, discriminative loss: 7.47418212890625
Iteration 233, total loss: 0.00026892079040408134, discriminative loss: 7.435601234436035
Iteration 234, total loss: 0.0002978952834382653, discriminative loss: 7.3496294021606445
Iteration 235, total loss: 0.00023935896751936525, discriminative loss: 7.5487542152404785
Iteration 236, total loss: 0.0002933886426035315, discriminative loss: 7.325685977935791
Iteration 237, total loss: 0.00037859680014662445, discriminative loss: 7.451100826263428
Iteration 238, total loss: 0.0002703975769691169, discriminative loss: 7.47638463973999
Iteration 239, total loss: 0.000322699430398643, discriminative loss: 7.4420247077941895
Iteration 240, total loss: 0.00024212988500948995, discriminative loss: 7.431533336639404
Iteration 241, total loss: 0.00026096776127815247, discriminative loss: 7.540271282196045
Iteration 242, total loss: 0.0002644339110702276, discriminative loss: 7.348029136657715
Iteration 243, total loss: 0.00034153778688050807, discriminative loss: 7.2435197830200195
Iteration 244, total loss: 0.0002347829140489921, discriminative loss: 7.495658874511719
Iteration 245, total loss: 0.00023957165831234306, discriminative loss: 7.4808197021484375
Iteration 246, total loss: 0.000323404383379966, discriminative loss: 7.373050212860107
Iteration 247, total loss: 0.0002607880742289126, discriminative loss: 7.312546730041504
Iteration 248, total loss: 0.00023702130420133471, discriminative loss: 7.445311546325684
Iteration 249, total loss: 0.0002552436199039221, discriminative loss: 7.381433486938477
Iteration 250, total loss: 0.00029298150911927223, discriminative loss: 7.544453144073486
Iteration 251, total loss: 0.00033391299075447023, discriminative loss: 7.380821228027344
Iteration 252, total loss: 0.00025245267897844315, discriminative loss: 7.398584842681885
Iteration 253, total loss: 0.0003279417578596622, discriminative loss: 7.481261253356934
Iteration 254, total loss: 0.00030291997245512903, discriminative loss: 7.600146770477295
Iteration 255, total loss: 0.00030334058101288974, discriminative loss: 7.47321891784668
Iteration 256, total loss: 0.00021721181110478938, discriminative loss: 7.510448455810547
Iteration 257, total loss: 0.00019939297635573894, discriminative loss: 7.443869590759277
Iteration 258, total loss: 0.00022131337027531117, discriminative loss: 7.655546188354492
Iteration 259, total loss: 0.0002538750122766942, discriminative loss: 7.37556266784668
Iteration 260, total loss: 0.00025985081447288394, discriminative loss: 7.354283332824707
Iteration 261, total loss: 0.0002496258239261806, discriminative loss: 7.449520587921143
Iteration 262, total loss: 0.0002768955018837005, discriminative loss: 7.442573547363281
Iteration 263, total loss: 0.00019875845464412123, discriminative loss: 7.245034217834473
Iteration 264, total loss: 0.00037164028617553413, discriminative loss: 7.486893653869629
Iteration 265, total loss: 0.00020958589448127896, discriminative loss: 7.400518894195557
Iteration 266, total loss: 0.00024386208679061383, discriminative loss: 7.153936386108398
Iteration 267, total loss: 0.00022920622723177075, discriminative loss: 7.331447601318359
Iteration 268, total loss: 0.00020895418128930032, discriminative loss: 7.570291996002197
Iteration 269, total loss: 0.0002451447071507573, discriminative loss: 7.570271015167236
Iteration 270, total loss: 0.00020579872943926603, discriminative loss: 7.263897895812988
Iteration 271, total loss: 0.00022517859179060906, discriminative loss: 7.580298900604248
Iteration 272, total loss: 0.00020451175805646926, discriminative loss: 7.386211395263672
Iteration 273, total loss: 0.00037996910396032035, discriminative loss: 7.4214091300964355
Iteration 274, total loss: 0.00022379972506314516, discriminative loss: 7.206289291381836
Iteration 275, total loss: 0.00021920439030509442, discriminative loss: 7.337407112121582
Iteration 276, total loss: 0.000262825662503019, discriminative loss: 7.445639610290527
Iteration 277, total loss: 0.00022844880004413426, discriminative loss: 7.611931324005127
Iteration 278, total loss: 0.0002262769703520462, discriminative loss: 7.265007972717285
Iteration 279, total loss: 0.000255287392064929, discriminative loss: 7.57049560546875
Iteration 280, total loss: 0.00021747153368778527, discriminative loss: 7.426762580871582
Iteration 281, total loss: 0.00028955552261322737, discriminative loss: 7.467121601104736
Iteration 282, total loss: 0.00018194140284322202, discriminative loss: 7.434454917907715
Iteration 283, total loss: 0.00024441489949822426, discriminative loss: 7.336382865905762
Iteration 284, total loss: 0.00036185665521770716, discriminative loss: 7.44847297668457
Iteration 285, total loss: 0.00020097318338230252, discriminative loss: 7.113597869873047
Iteration 286, total loss: 0.00020403058442752808, discriminative loss: 7.516247749328613
Iteration 287, total loss: 0.00020497273362707347, discriminative loss: 7.4595627784729
Iteration 288, total loss: 0.00021353417832870036, discriminative loss: 7.331539630889893
Iteration 289, total loss: 0.00020508249872364104, discriminative loss: 7.332187652587891
Iteration 290, total loss: 0.0002222434850409627, discriminative loss: 7.26147985458374
Iteration 291, total loss: 0.0002160987933166325, discriminative loss: 7.437193870544434
Iteration 292, total loss: 0.0001730114599922672, discriminative loss: 7.4120354652404785
Iteration 293, total loss: 0.00019244026043452322, discriminative loss: 7.386404991149902
Iteration 294, total loss: 0.00025391773669980466, discriminative loss: 7.4476776123046875
Iteration 295, total loss: 0.0001801297185011208, discriminative loss: 7.2879838943481445
Iteration 296, total loss: 0.00018186878878623247, discriminative loss: 7.472232818603516
Iteration 297, total loss: 0.00020456955826375633, discriminative loss: 7.19826602935791
Iteration 298, total loss: 0.00027976237470284104, discriminative loss: 7.499175071716309
Iteration 299, total loss: 0.00017165263125207275, discriminative loss: 7.519412994384766
Iteration 300, total loss: 0.00018958660075441003, discriminative loss: 7.398155212402344
Iteration 301, total loss: 0.00025386945344507694, discriminative loss: 7.48796272277832
Iteration 302, total loss: 0.00020399926870595664, discriminative loss: 7.3878607749938965
Iteration 303, total loss: 0.0001768048678059131, discriminative loss: 7.465618133544922
Iteration 304, total loss: 0.00017060211393982172, discriminative loss: 7.39924430847168
Iteration 305, total loss: 0.00018600084877107292, discriminative loss: 7.274863243103027
Iteration 306, total loss: 0.00023270570090971887, discriminative loss: 7.548820972442627
Iteration 307, total loss: 0.0002245109499199316, discriminative loss: 7.630549430847168
Iteration 308, total loss: 0.00017971626948565245, discriminative loss: 7.512869834899902
Iteration 309, total loss: 0.0002263165806652978, discriminative loss: 7.529417037963867
Iteration 310, total loss: 0.000172297382960096, discriminative loss: 7.44525146484375
Iteration 311, total loss: 0.0001879698975244537, discriminative loss: 7.411652088165283
Iteration 312, total loss: 0.00019774181419052184, discriminative loss: 7.368326663970947
Iteration 313, total loss: 0.00020452056196518242, discriminative loss: 7.423011302947998
Iteration 314, total loss: 0.00021632711286656559, discriminative loss: 7.265091896057129
Iteration 315, total loss: 0.00025634613120928407, discriminative loss: 7.634415149688721
Iteration 316, total loss: 0.00016725313616916537, discriminative loss: 7.564701557159424
Iteration 317, total loss: 0.00018954920233227313, discriminative loss: 7.443042755126953
Iteration 318, total loss: 0.00015425542369484901, discriminative loss: 7.374103546142578
Iteration 319, total loss: 0.00020832038717344403, discriminative loss: 7.605743408203125
Iteration 320, total loss: 0.00020519993267953396, discriminative loss: 7.448977470397949
Iteration 321, total loss: 0.0002893756900448352, discriminative loss: 7.504222869873047
Iteration 322, total loss: 0.00019908009562641382, discriminative loss: 7.3647966384887695
Iteration 323, total loss: 0.0001950080186361447, discriminative loss: 7.403331756591797
Iteration 324, total loss: 0.00024645726080052555, discriminative loss: 7.47939395904541
Iteration 325, total loss: 0.00018103828188031912, discriminative loss: 7.6276469230651855
Iteration 326, total loss: 0.0001985653943847865, discriminative loss: 7.248926162719727
Iteration 327, total loss: 0.00019150209845975041, discriminative loss: 7.2014055252075195
Iteration 328, total loss: 0.00019510863057803363, discriminative loss: 7.0694427490234375
Iteration 329, total loss: 0.0002371339505771175, discriminative loss: 7.6007490158081055
Iteration 330, total loss: 0.00018938296125270426, discriminative loss: 7.539187431335449
Iteration 331, total loss: 0.00019540070206858218, discriminative loss: 7.448694229125977
Iteration 332, total loss: 0.00021212207502685487, discriminative loss: 7.354292869567871
Iteration 333, total loss: 0.0001917385816341266, discriminative loss: 7.466745376586914
Iteration 334, total loss: 0.0001907404512166977, discriminative loss: 7.384360313415527
Iteration 335, total loss: 0.00023610255448147655, discriminative loss: 7.507140159606934
Iteration 336, total loss: 0.00016755405522417277, discriminative loss: 7.386908054351807
Iteration 337, total loss: 0.00017429869330953807, discriminative loss: 7.353128433227539
Iteration 338, total loss: 0.00018914713291451335, discriminative loss: 7.451992511749268
Iteration 339, total loss: 0.0001501758670201525, discriminative loss: 7.316985130310059
Iteration 340, total loss: 0.0001818901946535334, discriminative loss: 7.3780717849731445
Iteration 341, total loss: 0.0001662176218815148, discriminative loss: 7.135300636291504
Iteration 342, total loss: 0.00012694289034698159, discriminative loss: 7.4797868728637695
Iteration 343, total loss: 0.00019199585949536413, discriminative loss: 7.467265605926514
Iteration 344, total loss: 0.00019574676116462797, discriminative loss: 7.454494476318359
Iteration 345, total loss: 0.0002676849835552275, discriminative loss: 7.337071895599365
Iteration 346, total loss: 0.00022879321477375925, discriminative loss: 7.5042500495910645
Iteration 347, total loss: 0.00017983373254537582, discriminative loss: 7.470836639404297
Iteration 348, total loss: 0.0001899248018162325, discriminative loss: 7.45751953125
Iteration 349, total loss: 0.00020410565775819123, discriminative loss: 7.344412326812744
Iteration 350, total loss: 0.00014850609295535833, discriminative loss: 7.558141708374023
Iteration 351, total loss: 0.00016040055197663605, discriminative loss: 7.404935836791992
Iteration 352, total loss: 0.00018847623141482472, discriminative loss: 7.281447887420654
Iteration 353, total loss: 0.00013927223335485905, discriminative loss: 7.565580368041992
Iteration 354, total loss: 0.0001365942443953827, discriminative loss: 7.48106575012207
Iteration 355, total loss: 0.000155541580170393, discriminative loss: 7.451310157775879
Iteration 356, total loss: 0.00019082683138549328, discriminative loss: 7.590651988983154
Iteration 357, total loss: 0.0001814389688661322, discriminative loss: 7.322654724121094
Iteration 358, total loss: 0.00017637762357480824, discriminative loss: 7.653892993927002
Iteration 359, total loss: 0.00017900578677654266, discriminative loss: 7.331315040588379
Iteration 360, total loss: 0.00016714344383217394, discriminative loss: 7.258008003234863
Iteration 361, total loss: 0.00015018739213701338, discriminative loss: 7.462451934814453
Iteration 362, total loss: 0.00015252589946612716, discriminative loss: 7.281826972961426
Iteration 363, total loss: 0.000150602514622733, discriminative loss: 7.38866662979126
Iteration 364, total loss: 0.000163244956638664, discriminative loss: 7.207314491271973
Iteration 365, total loss: 0.00019608215370681137, discriminative loss: 7.351536750793457
Iteration 366, total loss: 0.00016178656369447708, discriminative loss: 7.602086067199707
Iteration 367, total loss: 0.00014696366270072758, discriminative loss: 7.292081832885742
Iteration 368, total loss: 0.00017031305469572544, discriminative loss: 7.329315185546875
Iteration 369, total loss: 0.00016307312762364745, discriminative loss: 7.579353332519531
Iteration 370, total loss: 0.00016815004346426576, discriminative loss: 7.472415447235107
Iteration 371, total loss: 0.00017611769726499915, discriminative loss: 7.333302021026611
Iteration 372, total loss: 0.00016376817075069994, discriminative loss: 7.499373912811279
Iteration 373, total loss: 0.00014319372712634504, discriminative loss: 7.078085899353027
Iteration 374, total loss: 0.00016831199172884226, discriminative loss: 7.3964338302612305
Iteration 375, total loss: 0.00016879636677913368, discriminative loss: 7.417611122131348
Iteration 376, total loss: 0.00016917980974540114, discriminative loss: 7.423708915710449
Iteration 377, total loss: 0.0001625528238946572, discriminative loss: 7.514965534210205
Iteration 378, total loss: 0.00016627789591439068, discriminative loss: 7.567687034606934
Iteration 379, total loss: 0.00020062596013303846, discriminative loss: 7.478936672210693
Iteration 380, total loss: 0.0001914214517455548, discriminative loss: 7.236823081970215
Iteration 381, total loss: 0.00014528012252412736, discriminative loss: 7.433610916137695
Iteration 382, total loss: 0.00015685794642195106, discriminative loss: 7.496092796325684
Iteration 383, total loss: 0.0001526441192254424, discriminative loss: 7.2311530113220215
Iteration 384, total loss: 0.00019576461636461318, discriminative loss: 7.310696125030518
Iteration 385, total loss: 0.00015377083036582917, discriminative loss: 7.369707107543945
Iteration 386, total loss: 0.00013960730575490743, discriminative loss: 7.359526634216309
Iteration 387, total loss: 0.00017572676006238908, discriminative loss: 7.430772304534912
Iteration 388, total loss: 0.0001217811368405819, discriminative loss: 7.494706630706787
Iteration 389, total loss: 0.0001950793230207637, discriminative loss: 7.491460800170898
Iteration 390, total loss: 0.0001318452850682661, discriminative loss: 7.396927356719971
Iteration 391, total loss: 0.00013377988943830132, discriminative loss: 7.49971342086792
Iteration 392, total loss: 0.00016321080329362303, discriminative loss: 7.383081436157227
Iteration 393, total loss: 0.00012350715405773371, discriminative loss: 7.554725646972656
Iteration 394, total loss: 0.0001459378399886191, discriminative loss: 7.31695556640625
Iteration 395, total loss: 0.00019783405878115445, discriminative loss: 7.274748802185059
Iteration 396, total loss: 0.00017735519213601947, discriminative loss: 7.363492965698242
Iteration 397, total loss: 0.00015366540173999965, discriminative loss: 7.448535919189453
Iteration 398, total loss: 0.0001493702584411949, discriminative loss: 7.529928684234619
Iteration 399, total loss: 0.0001639960682950914, discriminative loss: 7.510442733764648
Iteration 400, total loss: 0.00012414829689078033, discriminative loss: 7.425860404968262
Iteration 401, total loss: 0.00018209470727015287, discriminative loss: 7.237133026123047
Iteration 402, total loss: 0.00018822417769115418, discriminative loss: 7.374166965484619
Iteration 403, total loss: 0.00014034006744623184, discriminative loss: 7.515570640563965
Iteration 404, total loss: 0.0001516246993560344, discriminative loss: 7.3632402420043945
Iteration 405, total loss: 0.0001542680838610977, discriminative loss: 7.628838062286377
Iteration 406, total loss: 0.00016358452558051795, discriminative loss: 7.357119560241699
Iteration 407, total loss: 0.00015234906459227204, discriminative loss: 7.543231010437012
Iteration 408, total loss: 0.00017538765678182244, discriminative loss: 7.2468414306640625
Iteration 409, total loss: 0.00011888060544151813, discriminative loss: 7.4508442878723145
Iteration 410, total loss: 0.0001702784647932276, discriminative loss: 7.508294105529785
Iteration 411, total loss: 0.00017184387252200395, discriminative loss: 7.334377288818359
Iteration 412, total loss: 0.00013575941557064652, discriminative loss: 7.270796775817871
Iteration 413, total loss: 0.0001572629698785022, discriminative loss: 7.541772365570068
Iteration 414, total loss: 0.00014756980817764997, discriminative loss: 7.4217071533203125
Iteration 415, total loss: 0.00012855656677857041, discriminative loss: 7.366942405700684
Iteration 416, total loss: 0.00018119746528100222, discriminative loss: 7.584273338317871
Iteration 417, total loss: 0.00014640511653851718, discriminative loss: 7.442869186401367
Iteration 418, total loss: 0.00018710008589550853, discriminative loss: 7.492467880249023
Iteration 419, total loss: 0.00014042296970728785, discriminative loss: 7.528522491455078
Iteration 420, total loss: 0.00011907934822374955, discriminative loss: 7.332920551300049
Iteration 421, total loss: 0.00019128259737044573, discriminative loss: 7.282073974609375
Iteration 422, total loss: 0.0001540715602459386, discriminative loss: 7.256908416748047
Iteration 423, total loss: 0.0001175063953269273, discriminative loss: 7.44465970993042
Iteration 424, total loss: 0.0001287508785026148, discriminative loss: 7.3606276512146
Iteration 425, total loss: 0.00013117046910338104, discriminative loss: 7.385681629180908
Iteration 426, total loss: 0.00013142082025296986, discriminative loss: 7.511327743530273
Iteration 427, total loss: 0.00013335849507711828, discriminative loss: 6.977909088134766
Iteration 428, total loss: 0.00014252618711907417, discriminative loss: 7.4315595626831055
Iteration 429, total loss: 0.00014574851957149804, discriminative loss: 7.590482234954834
Iteration 430, total loss: 0.00013608430163003504, discriminative loss: 7.469133377075195
Iteration 431, total loss: 0.00015670512220822275, discriminative loss: 7.354741096496582
Iteration 432, total loss: 0.00012419867562130094, discriminative loss: 7.361898422241211
Iteration 433, total loss: 0.00016952375881373882, discriminative loss: 7.393149375915527
Iteration 434, total loss: 0.00016073280130513012, discriminative loss: 7.5544538497924805
Iteration 435, total loss: 0.00012193360453238711, discriminative loss: 7.320019721984863
Iteration 436, total loss: 0.00015222057118080556, discriminative loss: 7.567170143127441
Iteration 437, total loss: 0.00011783999798353761, discriminative loss: 7.650339126586914
Iteration 438, total loss: 0.00013085828686598688, discriminative loss: 7.273614883422852
Iteration 439, total loss: 0.00014208532229531556, discriminative loss: 7.331480026245117
Iteration 440, total loss: 0.00014699467283207923, discriminative loss: 7.631731986999512
Iteration 441, total loss: 0.00013432343257591128, discriminative loss: 7.604029178619385
Iteration 442, total loss: 0.00016606634017080069, discriminative loss: 7.315430641174316
Iteration 443, total loss: 0.0001451051066396758, discriminative loss: 7.20900297164917
Iteration 444, total loss: 0.00014561838179361075, discriminative loss: 7.55550479888916
Iteration 445, total loss: 0.00013318881974555552, discriminative loss: 7.486180305480957
Iteration 446, total loss: 0.00014251279935706407, discriminative loss: 7.379606246948242
Iteration 447, total loss: 0.00014277773152571172, discriminative loss: 7.53001594543457
Iteration 448, total loss: 0.00014463634579442441, discriminative loss: 7.435524940490723
Iteration 449, total loss: 0.00011991855717496946, discriminative loss: 7.239075183868408
Iteration 450, total loss: 0.00010069732525153086, discriminative loss: 7.219596862792969
Iteration 451, total loss: 0.00014502080739475787, discriminative loss: 7.3183979988098145
Iteration 452, total loss: 0.00012195267481729388, discriminative loss: 7.52635383605957
Iteration 453, total loss: 0.00011954666842939332, discriminative loss: 7.221208572387695
Iteration 454, total loss: 0.00012799577962141484, discriminative loss: 7.482182502746582
Iteration 455, total loss: 0.00012016551045235246, discriminative loss: 7.085912704467773
Iteration 456, total loss: 0.00014103711873758584, discriminative loss: 7.3148603439331055
Iteration 457, total loss: 0.00012928475916851312, discriminative loss: 7.5143280029296875
Iteration 458, total loss: 0.00012707327550742775, discriminative loss: 7.278491020202637
Iteration 459, total loss: 0.0001350826205452904, discriminative loss: 7.166119575500488
Iteration 460, total loss: 0.00012637476902455091, discriminative loss: 7.264134407043457
Iteration 461, total loss: 0.00012384779984131455, discriminative loss: 7.491642951965332
Iteration 462, total loss: 0.00013615495117846876, discriminative loss: 7.532834529876709
Iteration 463, total loss: 0.00011873077164636925, discriminative loss: 7.247462272644043
Iteration 464, total loss: 0.00013823292101733387, discriminative loss: 7.432037830352783
Iteration 465, total loss: 0.0001428962277714163, discriminative loss: 7.604885101318359
Iteration 466, total loss: 0.0001249939959961921, discriminative loss: 7.216360092163086
Iteration 467, total loss: 0.0001232099166372791, discriminative loss: 7.330428123474121
Iteration 468, total loss: 0.000113739661173895, discriminative loss: 7.370595455169678
Iteration 469, total loss: 0.00015446997713297606, discriminative loss: 7.383980751037598
Iteration 470, total loss: 0.0001262781152036041, discriminative loss: 7.457243919372559
Iteration 471, total loss: 0.00013117518392391503, discriminative loss: 7.313824653625488
Iteration 472, total loss: 0.00012221935321576893, discriminative loss: 7.355447769165039
Iteration 473, total loss: 0.00011224859918002039, discriminative loss: 7.66792631149292
Iteration 474, total loss: 0.00011722211638698354, discriminative loss: 7.243321418762207
Iteration 475, total loss: 0.00012191890709800646, discriminative loss: 7.597116947174072
Iteration 476, total loss: 0.00010469664994161576, discriminative loss: 7.39711856842041
Iteration 477, total loss: 0.00012863193114753813, discriminative loss: 7.5020623207092285
Iteration 478, total loss: 9.748766024131328e-05, discriminative loss: 7.338268756866455
Iteration 479, total loss: 0.00013238312385510653, discriminative loss: 7.514400959014893
Iteration 480, total loss: 0.00013443864008877426, discriminative loss: 7.239467144012451
Iteration 481, total loss: 0.000122603407362476, discriminative loss: 7.328683853149414
Iteration 482, total loss: 0.00011094546789536253, discriminative loss: 7.514822006225586
Iteration 483, total loss: 0.00010815184214152396, discriminative loss: 7.686984062194824
Iteration 484, total loss: 0.00010110684524988756, discriminative loss: 7.542949199676514
Iteration 485, total loss: 0.00012158532626926899, discriminative loss: 7.601381301879883
Iteration 486, total loss: 0.00011462772818049416, discriminative loss: 7.260957717895508
Iteration 487, total loss: 0.00011042470578104258, discriminative loss: 7.375866889953613
Iteration 488, total loss: 0.00010758949065348133, discriminative loss: 7.523916244506836
Iteration 489, total loss: 0.00013267739268485457, discriminative loss: 7.582026481628418
Iteration 490, total loss: 0.0001388467353535816, discriminative loss: 7.584073066711426
Iteration 491, total loss: 0.00010864456999115646, discriminative loss: 7.554746627807617
Iteration 492, total loss: 0.00010549015860306099, discriminative loss: 7.623269081115723
Iteration 493, total loss: 0.00013215745275374502, discriminative loss: 7.4140496253967285
Iteration 494, total loss: 0.00010317130363546312, discriminative loss: 7.192673206329346
Iteration 495, total loss: 0.00010957104677800089, discriminative loss: 7.491671562194824
Iteration 496, total loss: 0.00011937893577851355, discriminative loss: 7.457108497619629
Iteration 497, total loss: 0.00011580123828025535, discriminative loss: 7.4477314949035645
Iteration 498, total loss: 9.403351577930152e-05, discriminative loss: 7.450867176055908
Iteration 499, total loss: 0.00011437700595706701, discriminative loss: 7.3524041175842285
Iteration 500, total loss: 9.339913231087849e-05, discriminative loss: 7.485783576965332
Iteration 501, total loss: 0.00012057113781338558, discriminative loss: 7.277746200561523
Iteration 502, total loss: 0.00010429471149109304, discriminative loss: 7.587673664093018
Iteration 503, total loss: 0.00012263555254321545, discriminative loss: 7.328582763671875
Iteration 504, total loss: 0.000119509466458112, discriminative loss: 7.256662845611572
Iteration 505, total loss: 0.00014606493641622365, discriminative loss: 7.382381439208984
Iteration 506, total loss: 0.00010958029452012852, discriminative loss: 7.482063293457031
Iteration 507, total loss: 0.00013057190517429262, discriminative loss: 7.419674396514893
Iteration 508, total loss: 0.00012497443822212517, discriminative loss: 7.485538482666016
Iteration 509, total loss: 0.0001502833911217749, discriminative loss: 7.47979736328125
Iteration 510, total loss: 0.00011705040378728881, discriminative loss: 7.305667400360107
Iteration 511, total loss: 0.00012840295676141977, discriminative loss: 7.677648544311523
Iteration 512, total loss: 0.0001763211184879765, discriminative loss: 7.32588529586792
Iteration 513, total loss: 0.00011080926196882501, discriminative loss: 7.489238262176514
Iteration 514, total loss: 0.0001253060036106035, discriminative loss: 7.318055629730225
Iteration 515, total loss: 9.253248572349548e-05, discriminative loss: 7.426209449768066
Iteration 516, total loss: 0.00013392649998422712, discriminative loss: 7.489097595214844
Iteration 517, total loss: 0.0001135948405135423, discriminative loss: 7.308629035949707
Iteration 518, total loss: 0.00010982568346662447, discriminative loss: 7.434203147888184
Iteration 519, total loss: 0.0002361811202717945, discriminative loss: 7.307402610778809
Iteration 520, total loss: 0.0001074355241144076, discriminative loss: 7.41008186340332
Iteration 521, total loss: 0.00013898679753765464, discriminative loss: 7.325231552124023
Iteration 522, total loss: 0.00012461136793717742, discriminative loss: 7.260834693908691
Iteration 523, total loss: 0.0001313885732088238, discriminative loss: 7.614068984985352
Iteration 524, total loss: 0.00013518855848815292, discriminative loss: 7.538403034210205
Iteration 525, total loss: 0.00012284662807360291, discriminative loss: 7.4730939865112305
Iteration 526, total loss: 0.00010618841770337895, discriminative loss: 7.509215831756592
Iteration 527, total loss: 0.00015403465658891946, discriminative loss: 7.446900844573975
Iteration 528, total loss: 9.993481216952205e-05, discriminative loss: 7.313386917114258
Iteration 529, total loss: 0.00011844228720292449, discriminative loss: 7.60642147064209
Iteration 530, total loss: 0.00011738233297364786, discriminative loss: 7.2680182456970215
Iteration 531, total loss: 8.759159391047433e-05, discriminative loss: 7.36819314956665
Iteration 532, total loss: 0.00010567950084805489, discriminative loss: 7.41572380065918
Iteration 533, total loss: 0.0001171305266325362, discriminative loss: 7.429651260375977
Iteration 534, total loss: 0.00011326133972033858, discriminative loss: 7.328988075256348
Iteration 535, total loss: 9.361517732031643e-05, discriminative loss: 7.557473182678223
Iteration 536, total loss: 0.00010811074753291905, discriminative loss: 7.402923107147217
Iteration 537, total loss: 0.000107450301584322, discriminative loss: 7.4255690574646
Iteration 538, total loss: 0.00011709473619703203, discriminative loss: 7.573116302490234
Iteration 539, total loss: 9.37647491809912e-05, discriminative loss: 7.491018295288086
Iteration 540, total loss: 0.00013442165800370276, discriminative loss: 7.314887046813965
Iteration 541, total loss: 0.00010560364898992702, discriminative loss: 7.371896743774414
Iteration 542, total loss: 0.00010965591354761273, discriminative loss: 7.4906744956970215
Iteration 543, total loss: 0.00013959991338197142, discriminative loss: 7.413573265075684
Iteration 544, total loss: 0.0001040087008732371, discriminative loss: 7.437522888183594
Iteration 545, total loss: 8.911307668313384e-05, discriminative loss: 7.496685981750488
Iteration 546, total loss: 0.0001280597789445892, discriminative loss: 7.383294105529785
Iteration 547, total loss: 9.554675489198416e-05, discriminative loss: 7.507755279541016
Iteration 548, total loss: 0.00012733219773508608, discriminative loss: 7.456998825073242
Iteration 549, total loss: 0.00012320809764787555, discriminative loss: 7.431067943572998
Iteration 550, total loss: 8.313601574627683e-05, discriminative loss: 7.551365852355957
Iteration 551, total loss: 0.0001257360418094322, discriminative loss: 7.43670654296875
Iteration 552, total loss: 0.00015439953131135553, discriminative loss: 7.377524375915527
Iteration 553, total loss: 9.288916771765798e-05, discriminative loss: 7.473316192626953
Iteration 554, total loss: 0.00011558221012819558, discriminative loss: 7.3244733810424805
Iteration 555, total loss: 0.00011171660298714414, discriminative loss: 7.398289203643799
Iteration 556, total loss: 0.00010564275726210326, discriminative loss: 7.691893577575684
Iteration 557, total loss: 0.00011650478700175881, discriminative loss: 7.481672286987305
Iteration 558, total loss: 0.00010357768042013049, discriminative loss: 7.483380317687988
Iteration 559, total loss: 0.00010579784429864958, discriminative loss: 7.477968215942383
Iteration 560, total loss: 9.358892566524446e-05, discriminative loss: 7.417636394500732
Iteration 561, total loss: 9.89400505204685e-05, discriminative loss: 7.456333160400391
Iteration 562, total loss: 0.0001062753435689956, discriminative loss: 7.475090980529785
Iteration 563, total loss: 0.0001374586281599477, discriminative loss: 7.4160356521606445
Iteration 564, total loss: 0.00010393127013230696, discriminative loss: 7.482227325439453
Iteration 565, total loss: 0.00010292800288880244, discriminative loss: 7.387684345245361
Iteration 566, total loss: 0.00011251890828134492, discriminative loss: 7.564580917358398
Iteration 567, total loss: 9.775681974133477e-05, discriminative loss: 7.220108985900879
Iteration 568, total loss: 0.00011583431478356943, discriminative loss: 7.274278163909912
Iteration 569, total loss: 0.00010289697092957795, discriminative loss: 7.3677144050598145
Iteration 570, total loss: 0.00010369056690251455, discriminative loss: 7.431724548339844
Iteration 571, total loss: 8.91981107997708e-05, discriminative loss: 7.600849151611328
Iteration 572, total loss: 0.00012215250171720982, discriminative loss: 7.644402503967285
Iteration 573, total loss: 8.951485506258905e-05, discriminative loss: 7.4630537033081055
Iteration 574, total loss: 0.00011457164509920403, discriminative loss: 7.367687225341797
Iteration 575, total loss: 0.00011215352424187586, discriminative loss: 7.521358966827393
Iteration 576, total loss: 0.00011963775614276528, discriminative loss: 7.45197057723999
Iteration 577, total loss: 0.00010790174565045163, discriminative loss: 7.63057804107666
Iteration 578, total loss: 9.041647717822343e-05, discriminative loss: 7.420192718505859
Iteration 579, total loss: 0.00012034882820444182, discriminative loss: 7.5279436111450195
Iteration 580, total loss: 9.947227226803079e-05, discriminative loss: 7.306899547576904
Iteration 581, total loss: 9.159526962321252e-05, discriminative loss: 7.446598052978516
Iteration 582, total loss: 0.00010056319297291338, discriminative loss: 7.3890581130981445
Iteration 583, total loss: 0.0001188106180052273, discriminative loss: 7.285017967224121
Iteration 584, total loss: 0.00011302945495117456, discriminative loss: 7.399752616882324
Iteration 585, total loss: 8.97715799510479e-05, discriminative loss: 7.567666053771973
Iteration 586, total loss: 0.00012322799011599272, discriminative loss: 7.660316467285156
Iteration 587, total loss: 0.00010933790326816961, discriminative loss: 7.206230640411377
Iteration 588, total loss: 0.00010926134564215317, discriminative loss: 7.441851615905762
Iteration 589, total loss: 0.00011201957386219874, discriminative loss: 7.518830299377441
Iteration 590, total loss: 0.00012119088933104649, discriminative loss: 7.236777305603027
Iteration 591, total loss: 0.00010134947660844773, discriminative loss: 7.506041049957275
Iteration 592, total loss: 0.00010789294174173847, discriminative loss: 7.452888488769531
Iteration 593, total loss: 9.84446523943916e-05, discriminative loss: 7.422634601593018
Iteration 594, total loss: 0.00010438865865580738, discriminative loss: 7.644543647766113
Iteration 595, total loss: 8.979778795037419e-05, discriminative loss: 7.531820774078369
Iteration 596, total loss: 0.0001723163586575538, discriminative loss: 7.572364330291748
Iteration 597, total loss: 8.943525608628988e-05, discriminative loss: 7.210061550140381
Iteration 598, total loss: 9.565446816850454e-05, discriminative loss: 7.347269058227539
Iteration 599, total loss: 0.00015547432121820748, discriminative loss: 7.362785339355469
Iteration 600, total loss: 8.576540130889043e-05, discriminative loss: 7.374447822570801
Iteration 601, total loss: 9.075671550817788e-05, discriminative loss: 7.446712970733643
Iteration 602, total loss: 0.00010970079893013462, discriminative loss: 7.293646812438965
Iteration 603, total loss: 0.00012442079605534673, discriminative loss: 7.452980041503906
Iteration 604, total loss: 0.00011171348887728527, discriminative loss: 7.3537516593933105
Iteration 605, total loss: 8.128048648359254e-05, discriminative loss: 7.273980140686035
Iteration 606, total loss: 0.0001174040517071262, discriminative loss: 7.35629415512085
Iteration 607, total loss: 0.00011424568947404623, discriminative loss: 7.5037336349487305
Iteration 608, total loss: 9.783165296539664e-05, discriminative loss: 7.509654998779297
Iteration 609, total loss: 0.000171827181475237, discriminative loss: 7.439162254333496
Iteration 610, total loss: 0.00010968776769004762, discriminative loss: 7.416567325592041
Iteration 611, total loss: 9.484530164627358e-05, discriminative loss: 7.462835311889648
Iteration 612, total loss: 0.00011173968960065395, discriminative loss: 7.399646759033203
Iteration 613, total loss: 0.00010167109576286748, discriminative loss: 7.444430828094482
Iteration 614, total loss: 8.417762001045048e-05, discriminative loss: 7.444728851318359
Iteration 615, total loss: 8.91960589797236e-05, discriminative loss: 7.338234901428223
Iteration 616, total loss: 9.314691124018282e-05, discriminative loss: 7.770444869995117
Iteration 617, total loss: 8.531782805221155e-05, discriminative loss: 7.344597339630127
Iteration 618, total loss: 8.326087845489383e-05, discriminative loss: 7.455987930297852
Iteration 619, total loss: 9.206307004205883e-05, discriminative loss: 7.282109260559082
Iteration 620, total loss: 8.050187898334116e-05, discriminative loss: 7.471918106079102
Iteration 621, total loss: 8.591365622123703e-05, discriminative loss: 7.196248531341553
Iteration 622, total loss: 0.0001243157166754827, discriminative loss: 7.336430549621582
Iteration 623, total loss: 8.027083822526038e-05, discriminative loss: 7.537158966064453
Iteration 624, total loss: 8.160900324583054e-05, discriminative loss: 7.636959075927734
Iteration 625, total loss: 0.00011943368008360267, discriminative loss: 7.3321709632873535
Iteration 626, total loss: 8.212576358346269e-05, discriminative loss: 7.329946517944336
Iteration 627, total loss: 8.497287490172312e-05, discriminative loss: 7.3481550216674805
Iteration 628, total loss: 7.855147850932553e-05, discriminative loss: 7.553877830505371
Iteration 629, total loss: 9.880716243060306e-05, discriminative loss: 7.312742233276367
Iteration 630, total loss: 9.828386100707576e-05, discriminative loss: 7.470234394073486
Iteration 631, total loss: 0.00011802779044955969, discriminative loss: 7.636116981506348
Iteration 632, total loss: 9.935534762917086e-05, discriminative loss: 7.5483012199401855
Iteration 633, total loss: 8.099996921373531e-05, discriminative loss: 7.321274757385254
Iteration 634, total loss: 0.0001376993750454858, discriminative loss: 7.4240312576293945
Iteration 635, total loss: 8.283433271571994e-05, discriminative loss: 7.151951789855957
Iteration 636, total loss: 0.00010649758769432083, discriminative loss: 7.421235084533691
Iteration 637, total loss: 8.108568727038801e-05, discriminative loss: 7.273766994476318
Iteration 638, total loss: 0.00010429261601530015, discriminative loss: 7.6983466148376465
Iteration 639, total loss: 8.479426469421014e-05, discriminative loss: 7.516780853271484
Iteration 640, total loss: 0.00018028717022389174, discriminative loss: 7.439176082611084
Iteration 641, total loss: 0.00010424535867059603, discriminative loss: 7.659780502319336
Iteration 642, total loss: 8.754854934522882e-05, discriminative loss: 7.256730556488037
Iteration 643, total loss: 9.154438157565892e-05, discriminative loss: 7.245973587036133
Iteration 644, total loss: 8.246724610216916e-05, discriminative loss: 7.4566850662231445
Iteration 645, total loss: 9.051380766322836e-05, discriminative loss: 7.34814453125
Iteration 646, total loss: 9.302880062023178e-05, discriminative loss: 7.371100902557373
Iteration 647, total loss: 8.503504795953631e-05, discriminative loss: 7.606044292449951
Iteration 648, total loss: 9.743443661136553e-05, discriminative loss: 7.504748344421387
Iteration 649, total loss: 8.98083599167876e-05, discriminative loss: 7.489960670471191
Iteration 650, total loss: 9.753603808348998e-05, discriminative loss: 7.701146125793457
Iteration 651, total loss: 8.444463310297579e-05, discriminative loss: 7.367914199829102
Iteration 652, total loss: 8.812414307612926e-05, discriminative loss: 7.256796360015869
Iteration 653, total loss: 0.00010945302346954122, discriminative loss: 7.304713249206543
Iteration 654, total loss: 9.847118781181052e-05, discriminative loss: 7.34785795211792
Iteration 655, total loss: 8.738946780795231e-05, discriminative loss: 7.320321083068848
Iteration 656, total loss: 7.984448893694207e-05, discriminative loss: 7.584868431091309
Iteration 657, total loss: 7.825418288121e-05, discriminative loss: 7.510598182678223
Iteration 658, total loss: 8.167958731064573e-05, discriminative loss: 7.5201568603515625
Iteration 659, total loss: 8.376120240427554e-05, discriminative loss: 7.2412519454956055
Iteration 660, total loss: 9.174015576718375e-05, discriminative loss: 7.371116638183594
Iteration 661, total loss: 0.00015566158981528133, discriminative loss: 7.240038871765137
Iteration 662, total loss: 7.651590567547828e-05, discriminative loss: 7.531280040740967
Iteration 663, total loss: 6.487104838015512e-05, discriminative loss: 7.180388927459717
Training completed
