Config: rmsprop, lambda=1.0, batch size=64, epochs=2

Using TensorFlow backend.
Reference model built
Secondary model built
Total number of iterations: 664
2018-06-24 08:44:50.041039: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:50.241776: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.40GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:50.397448: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.22GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:50.776597: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:50.944945: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:51.651344: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:52.301247: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:44:52.551733: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Iteration 0, total loss: 8.062716484069824, discriminative loss: 7.980335235595703
Iteration 1, total loss: 39459.5546875, discriminative loss: 16.11809539794922
Iteration 2, total loss: 7.139660835266113, discriminative loss: 7.139660835266113
Iteration 3, total loss: 7.31856107711792, discriminative loss: 7.318560600280762
Iteration 4, total loss: 7.134847640991211, discriminative loss: 7.134847640991211
Iteration 5, total loss: 7.0829010009765625, discriminative loss: 7.0829010009765625
Iteration 6, total loss: 7.264760971069336, discriminative loss: 7.264760971069336
Iteration 7, total loss: 7.138072967529297, discriminative loss: 7.138072967529297
Iteration 8, total loss: 7.150516510009766, discriminative loss: 7.150516510009766
Iteration 9, total loss: 7.056332111358643, discriminative loss: 7.056332111358643
Iteration 10, total loss: 7.112748146057129, discriminative loss: 7.112748146057129
Iteration 11, total loss: 7.027629852294922, discriminative loss: 7.027629852294922
Iteration 12, total loss: 7.370945930480957, discriminative loss: 7.370945930480957
Iteration 13, total loss: 7.185376167297363, discriminative loss: 7.185376167297363
Iteration 14, total loss: 7.103299140930176, discriminative loss: 7.103299140930176
Iteration 15, total loss: 7.112648010253906, discriminative loss: 7.112648010253906
Iteration 16, total loss: 7.227814674377441, discriminative loss: 7.227814674377441
Iteration 17, total loss: 7.025620460510254, discriminative loss: 7.025620460510254
Iteration 18, total loss: 7.100925445556641, discriminative loss: 7.100925445556641
Iteration 19, total loss: 7.157919883728027, discriminative loss: 7.157919883728027
Iteration 20, total loss: 7.25523567199707, discriminative loss: 7.25523567199707
Iteration 21, total loss: 6.991251468658447, discriminative loss: 6.991251468658447
Iteration 22, total loss: 7.079418659210205, discriminative loss: 7.079418659210205
Iteration 23, total loss: 7.064194202423096, discriminative loss: 7.064194202423096
Iteration 24, total loss: 7.147076606750488, discriminative loss: 7.147076606750488
Iteration 25, total loss: 7.0921430587768555, discriminative loss: 7.0921430587768555
Iteration 26, total loss: 7.098862648010254, discriminative loss: 7.098862648010254
Iteration 27, total loss: 7.195861339569092, discriminative loss: 7.195861339569092
Iteration 28, total loss: 7.0939741134643555, discriminative loss: 7.0939741134643555
Iteration 29, total loss: 7.240955352783203, discriminative loss: 7.240955352783203
Iteration 30, total loss: 7.155092239379883, discriminative loss: 7.155092239379883
Iteration 31, total loss: 7.013692855834961, discriminative loss: 7.013692855834961
Iteration 32, total loss: 7.155616760253906, discriminative loss: 7.155616760253906
Iteration 33, total loss: 7.294292449951172, discriminative loss: 7.294292449951172
Iteration 34, total loss: 7.2278547286987305, discriminative loss: 7.2278547286987305
Iteration 35, total loss: 7.104203701019287, discriminative loss: 7.104203701019287
Iteration 36, total loss: 7.232457160949707, discriminative loss: 7.232457160949707
Iteration 37, total loss: 7.17879581451416, discriminative loss: 7.17879581451416
Iteration 38, total loss: 7.068205833435059, discriminative loss: 7.068205833435059
Iteration 39, total loss: 6.937249660491943, discriminative loss: 6.937249660491943
Iteration 40, total loss: 7.04807186126709, discriminative loss: 7.04807186126709
Iteration 41, total loss: 7.282521724700928, discriminative loss: 7.2825212478637695
Iteration 42, total loss: 6.997776031494141, discriminative loss: 6.997776031494141
Iteration 43, total loss: 7.182571887969971, discriminative loss: 7.182571887969971
Iteration 44, total loss: 7.1699371337890625, discriminative loss: 7.1699371337890625
Iteration 45, total loss: 7.277179718017578, discriminative loss: 7.277179718017578
Iteration 46, total loss: 7.093015670776367, discriminative loss: 7.093015670776367
Iteration 47, total loss: 7.15260124206543, discriminative loss: 7.15260124206543
Iteration 48, total loss: 7.186295032501221, discriminative loss: 7.186295032501221
Iteration 49, total loss: 7.065417289733887, discriminative loss: 7.065417289733887
Iteration 50, total loss: 7.1008405685424805, discriminative loss: 7.1008405685424805
Iteration 51, total loss: 7.3166632652282715, discriminative loss: 7.3166632652282715
Iteration 52, total loss: 7.142034530639648, discriminative loss: 7.142034530639648
Iteration 53, total loss: 7.190276145935059, discriminative loss: 7.190276145935059
Iteration 54, total loss: 7.202827453613281, discriminative loss: 7.202827453613281
Iteration 55, total loss: 7.087725639343262, discriminative loss: 7.087725639343262
Iteration 56, total loss: 7.1531171798706055, discriminative loss: 7.1531171798706055
Iteration 57, total loss: 7.091765403747559, discriminative loss: 7.091765403747559
Iteration 58, total loss: 7.064155101776123, discriminative loss: 7.064155101776123
Iteration 59, total loss: 7.265395164489746, discriminative loss: 7.265395164489746
Iteration 60, total loss: 7.1763081550598145, discriminative loss: 7.1763081550598145
Iteration 61, total loss: 7.115261554718018, discriminative loss: 7.115261554718018
Iteration 62, total loss: 7.074527740478516, discriminative loss: 7.074527740478516
Iteration 63, total loss: 7.272480010986328, discriminative loss: 7.272480010986328
Iteration 64, total loss: 7.301041603088379, discriminative loss: 7.301041603088379
Iteration 65, total loss: 7.109461784362793, discriminative loss: 7.109461784362793
Iteration 66, total loss: 7.248476028442383, discriminative loss: 7.248476028442383
Iteration 67, total loss: 7.099713325500488, discriminative loss: 7.099713325500488
Iteration 68, total loss: 7.062453746795654, discriminative loss: 7.062453746795654
Iteration 69, total loss: 7.000149726867676, discriminative loss: 7.000149726867676
Iteration 70, total loss: 7.249621391296387, discriminative loss: 7.249621391296387
Iteration 71, total loss: 7.180052280426025, discriminative loss: 7.180052280426025
Iteration 72, total loss: 7.270117282867432, discriminative loss: 7.270117282867432
Iteration 73, total loss: 7.320404529571533, discriminative loss: 7.320404529571533
Iteration 74, total loss: 7.193145751953125, discriminative loss: 7.193145751953125
Iteration 75, total loss: 7.151289939880371, discriminative loss: 7.151289939880371
Iteration 76, total loss: 7.098020553588867, discriminative loss: 7.098020553588867
Iteration 77, total loss: 7.0587921142578125, discriminative loss: 7.0587921142578125
Iteration 78, total loss: 7.2958269119262695, discriminative loss: 7.2958269119262695
Iteration 79, total loss: 7.335893154144287, discriminative loss: 7.335893154144287
Iteration 80, total loss: 7.243827819824219, discriminative loss: 7.243827819824219
Iteration 81, total loss: 7.207235336303711, discriminative loss: 7.207235336303711
Iteration 82, total loss: 7.271271705627441, discriminative loss: 7.271271705627441
Iteration 83, total loss: 7.2112202644348145, discriminative loss: 7.2112202644348145
Iteration 84, total loss: 7.291487216949463, discriminative loss: 7.291487216949463
Iteration 85, total loss: 7.148392677307129, discriminative loss: 7.148392677307129
Iteration 86, total loss: 7.165584087371826, discriminative loss: 7.165584087371826
Iteration 87, total loss: 7.26659631729126, discriminative loss: 7.26659631729126
Iteration 88, total loss: 7.145114898681641, discriminative loss: 7.145114898681641
Iteration 89, total loss: 7.0505266189575195, discriminative loss: 7.0505266189575195
Iteration 90, total loss: 7.044618606567383, discriminative loss: 7.044618606567383
Iteration 91, total loss: 7.060848236083984, discriminative loss: 7.060848236083984
Iteration 92, total loss: 7.080726623535156, discriminative loss: 7.080726623535156
Iteration 93, total loss: 7.131381988525391, discriminative loss: 7.131381988525391
Iteration 94, total loss: 7.19254207611084, discriminative loss: 7.19254207611084
Iteration 95, total loss: 7.1015520095825195, discriminative loss: 7.1015520095825195
Iteration 96, total loss: 7.046523094177246, discriminative loss: 7.046523094177246
Iteration 97, total loss: 7.105826377868652, discriminative loss: 7.105826377868652
Iteration 98, total loss: 7.222717761993408, discriminative loss: 7.222717761993408
Iteration 99, total loss: 7.112527370452881, discriminative loss: 7.112527370452881
Iteration 100, total loss: 7.2415876388549805, discriminative loss: 7.2415876388549805
Iteration 101, total loss: 7.107922554016113, discriminative loss: 7.107922554016113
Iteration 102, total loss: 7.200002670288086, discriminative loss: 7.200002670288086
Iteration 103, total loss: 7.077570915222168, discriminative loss: 7.077570915222168
Iteration 104, total loss: 7.190648078918457, discriminative loss: 7.190648078918457
Iteration 105, total loss: 7.092473030090332, discriminative loss: 7.092473030090332
Iteration 106, total loss: 7.110415935516357, discriminative loss: 7.110415935516357
Iteration 107, total loss: 7.149158000946045, discriminative loss: 7.149158000946045
Iteration 108, total loss: 7.136148452758789, discriminative loss: 7.136148452758789
Iteration 109, total loss: 7.05432653427124, discriminative loss: 7.05432653427124
Iteration 110, total loss: 7.081526279449463, discriminative loss: 7.081526279449463
Iteration 111, total loss: 7.193907260894775, discriminative loss: 7.193907260894775
Iteration 112, total loss: 7.135023593902588, discriminative loss: 7.135023593902588
Iteration 113, total loss: 6.978020668029785, discriminative loss: 6.978020668029785
Iteration 114, total loss: 7.140803337097168, discriminative loss: 7.140803337097168
Iteration 115, total loss: 7.168265342712402, discriminative loss: 7.168265342712402
Iteration 116, total loss: 7.052964210510254, discriminative loss: 7.052964210510254
Iteration 117, total loss: 7.028408050537109, discriminative loss: 7.028408050537109
Iteration 118, total loss: 7.077877998352051, discriminative loss: 7.077877998352051
Iteration 119, total loss: 7.180729389190674, discriminative loss: 7.180729389190674
Iteration 120, total loss: 7.190478324890137, discriminative loss: 7.190478324890137
Iteration 121, total loss: 7.189280986785889, discriminative loss: 7.189280986785889
Iteration 122, total loss: 7.272194862365723, discriminative loss: 7.272194862365723
Iteration 123, total loss: 7.297467231750488, discriminative loss: 7.297467231750488
Iteration 124, total loss: 7.360835075378418, discriminative loss: 7.360835075378418
Iteration 125, total loss: 7.331593990325928, discriminative loss: 7.331593990325928
Iteration 126, total loss: 7.002127647399902, discriminative loss: 7.002127647399902
Iteration 127, total loss: 7.236699104309082, discriminative loss: 7.236699104309082
Iteration 128, total loss: 7.306931972503662, discriminative loss: 7.306931972503662
Iteration 129, total loss: 7.2409515380859375, discriminative loss: 7.2409515380859375
Iteration 130, total loss: 7.304173469543457, discriminative loss: 7.304173469543457
Iteration 131, total loss: 7.246077537536621, discriminative loss: 7.246077537536621
Iteration 132, total loss: 7.206157207489014, discriminative loss: 7.206157207489014
Iteration 133, total loss: 7.263998031616211, discriminative loss: 7.263998031616211
Iteration 134, total loss: 7.286199569702148, discriminative loss: 7.286199569702148
Iteration 135, total loss: 7.241447925567627, discriminative loss: 7.241447925567627
Iteration 136, total loss: 7.213070392608643, discriminative loss: 7.213070392608643
Iteration 137, total loss: 7.302596569061279, discriminative loss: 7.302596569061279
Iteration 138, total loss: 7.069338798522949, discriminative loss: 7.069338798522949
Iteration 139, total loss: 7.1742095947265625, discriminative loss: 7.1742095947265625
Iteration 140, total loss: 7.1078667640686035, discriminative loss: 7.1078667640686035
Iteration 141, total loss: 7.077131271362305, discriminative loss: 7.077131271362305
Iteration 142, total loss: 7.159543037414551, discriminative loss: 7.159543037414551
Iteration 143, total loss: 7.38172721862793, discriminative loss: 7.38172721862793
Iteration 144, total loss: 7.10044002532959, discriminative loss: 7.10044002532959
Iteration 145, total loss: 7.242070198059082, discriminative loss: 7.242070198059082
Iteration 146, total loss: 7.186799049377441, discriminative loss: 7.186799049377441
Iteration 147, total loss: 7.134106636047363, discriminative loss: 7.134106636047363
Iteration 148, total loss: 7.201342582702637, discriminative loss: 7.201342582702637
Iteration 149, total loss: 7.287282943725586, discriminative loss: 7.287282943725586
Iteration 150, total loss: 7.232729911804199, discriminative loss: 7.232729911804199
Iteration 151, total loss: 7.218323707580566, discriminative loss: 7.218323707580566
Iteration 152, total loss: 7.046499252319336, discriminative loss: 7.046499252319336
Iteration 153, total loss: 7.010210037231445, discriminative loss: 7.010210037231445
Iteration 154, total loss: 7.134365081787109, discriminative loss: 7.134365081787109
Iteration 155, total loss: 7.1305694580078125, discriminative loss: 7.1305694580078125
Iteration 156, total loss: 7.16876220703125, discriminative loss: 7.16876220703125
Iteration 157, total loss: 7.220133304595947, discriminative loss: 7.220133304595947
Iteration 158, total loss: 7.173818588256836, discriminative loss: 7.173818588256836
Iteration 159, total loss: 6.994693756103516, discriminative loss: 6.994693756103516
Iteration 160, total loss: 7.180008411407471, discriminative loss: 7.180008411407471
Iteration 161, total loss: 7.261264801025391, discriminative loss: 7.261264801025391
Iteration 162, total loss: 7.148362636566162, discriminative loss: 7.148362636566162
Iteration 163, total loss: 7.181939125061035, discriminative loss: 7.181939125061035
Iteration 164, total loss: 7.431670188903809, discriminative loss: 7.431670188903809
Iteration 165, total loss: 7.274555206298828, discriminative loss: 7.274555206298828
Iteration 166, total loss: 7.225460052490234, discriminative loss: 7.225460052490234
Iteration 167, total loss: 7.172296524047852, discriminative loss: 7.172296524047852
Iteration 168, total loss: 7.096236228942871, discriminative loss: 7.096236228942871
Iteration 169, total loss: 7.194230556488037, discriminative loss: 7.194230556488037
Iteration 170, total loss: 7.092344284057617, discriminative loss: 7.092344284057617
Iteration 171, total loss: 7.207199573516846, discriminative loss: 7.207199573516846
Iteration 172, total loss: 7.308052062988281, discriminative loss: 7.308052062988281
Iteration 173, total loss: 7.272676467895508, discriminative loss: 7.272676467895508
Iteration 174, total loss: 7.327341556549072, discriminative loss: 7.327341556549072
Iteration 175, total loss: 7.191396713256836, discriminative loss: 7.191396713256836
Iteration 176, total loss: 7.125162124633789, discriminative loss: 7.125162124633789
Iteration 177, total loss: 7.076704025268555, discriminative loss: 7.076704025268555
Iteration 178, total loss: 7.233063697814941, discriminative loss: 7.233063697814941
Iteration 179, total loss: 7.026024341583252, discriminative loss: 7.026024341583252
Iteration 180, total loss: 7.213720321655273, discriminative loss: 7.213720321655273
Iteration 181, total loss: 7.235297203063965, discriminative loss: 7.235297203063965
Iteration 182, total loss: 7.090018272399902, discriminative loss: 7.090018272399902
Iteration 183, total loss: 7.182517051696777, discriminative loss: 7.182517051696777
Iteration 184, total loss: 7.117952823638916, discriminative loss: 7.117952823638916
2018-06-24 08:49:14.563170: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.72GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-24 08:49:14.563253: W tensorflow/stream_executor/cuda/cuda_dnn.cc:3797]
Iteration 185, total loss: 7.259458541870117, discriminative loss: 7.259458541870117
Iteration 186, total loss: 7.137977600097656, discriminative loss: 7.137977600097656
Iteration 187, total loss: 7.090696334838867, discriminative loss: 7.090696334838867
Iteration 188, total loss: 7.024868965148926, discriminative loss: 7.024868965148926
Iteration 189, total loss: 7.315617561340332, discriminative loss: 7.315617561340332
Iteration 190, total loss: 7.057235240936279, discriminative loss: 7.057235240936279
Iteration 191, total loss: 6.95578145980835, discriminative loss: 6.95578145980835
Iteration 192, total loss: 7.378491401672363, discriminative loss: 7.378491401672363
Iteration 193, total loss: 7.15910005569458, discriminative loss: 7.15910005569458
Iteration 194, total loss: 7.023214817047119, discriminative loss: 7.023214817047119
Iteration 195, total loss: 7.273993015289307, discriminative loss: 7.273993015289307
Iteration 196, total loss: 7.222832679748535, discriminative loss: 7.222832679748535
Iteration 197, total loss: 7.206550598144531, discriminative loss: 7.206550598144531
Iteration 198, total loss: 7.314508438110352, discriminative loss: 7.314508438110352
Iteration 199, total loss: 7.215528964996338, discriminative loss: 7.215528964996338
Iteration 200, total loss: 7.204841613769531, discriminative loss: 7.204841613769531
Iteration 201, total loss: 6.953193187713623, discriminative loss: 6.953193187713623
Iteration 202, total loss: 7.112630367279053, discriminative loss: 7.112630367279053
Iteration 203, total loss: 7.086688995361328, discriminative loss: 7.086688995361328
Iteration 204, total loss: 7.120284557342529, discriminative loss: 7.120284557342529
Iteration 205, total loss: 7.1731038093566895, discriminative loss: 7.1731038093566895
Iteration 206, total loss: 7.102022647857666, discriminative loss: 7.102022647857666
Iteration 207, total loss: 7.285146713256836, discriminative loss: 7.285146713256836
Iteration 208, total loss: 7.121596813201904, discriminative loss: 7.121596813201904
Iteration 209, total loss: 7.415774345397949, discriminative loss: 7.415774345397949
Iteration 210, total loss: 7.077332496643066, discriminative loss: 7.077332496643066
Iteration 211, total loss: 7.053520202636719, discriminative loss: 7.053520202636719
Iteration 212, total loss: 7.2000298500061035, discriminative loss: 7.2000298500061035
Iteration 213, total loss: 7.199294090270996, discriminative loss: 7.199294090270996
Iteration 214, total loss: 7.159981727600098, discriminative loss: 7.159981727600098
Iteration 215, total loss: 7.1908721923828125, discriminative loss: 7.1908721923828125
Iteration 216, total loss: 7.033881187438965, discriminative loss: 7.033881187438965
Iteration 217, total loss: 7.193753242492676, discriminative loss: 7.193753242492676
Iteration 218, total loss: 7.1014933586120605, discriminative loss: 7.1014933586120605
Iteration 219, total loss: 7.37786865234375, discriminative loss: 7.37786865234375
Iteration 220, total loss: 7.212242126464844, discriminative loss: 7.212242126464844
Iteration 221, total loss: 7.131171226501465, discriminative loss: 7.131171226501465
Iteration 222, total loss: 7.172531604766846, discriminative loss: 7.172531604766846
Iteration 223, total loss: 7.141587734222412, discriminative loss: 7.141587734222412
Iteration 224, total loss: 7.256424903869629, discriminative loss: 7.256424903869629
Iteration 225, total loss: 7.146366596221924, discriminative loss: 7.146366596221924
Iteration 226, total loss: 7.059478759765625, discriminative loss: 7.059478759765625
Iteration 227, total loss: 7.116634845733643, discriminative loss: 7.116634845733643
Iteration 228, total loss: 7.279061794281006, discriminative loss: 7.279061794281006
Iteration 229, total loss: 7.213744640350342, discriminative loss: 7.213744640350342
Iteration 230, total loss: 7.082999229431152, discriminative loss: 7.082999229431152
Iteration 231, total loss: 7.146397590637207, discriminative loss: 7.146397590637207
Iteration 232, total loss: 7.05472993850708, discriminative loss: 7.05472993850708
Iteration 233, total loss: 7.247346878051758, discriminative loss: 7.247346878051758
Iteration 234, total loss: 7.035113334655762, discriminative loss: 7.035113334655762
Iteration 235, total loss: 7.155513763427734, discriminative loss: 7.155513763427734
Iteration 236, total loss: 7.146182060241699, discriminative loss: 7.146182060241699
Iteration 237, total loss: 7.209633827209473, discriminative loss: 7.209633827209473
Iteration 238, total loss: 7.113025665283203, discriminative loss: 7.113025665283203
Iteration 239, total loss: 7.242467880249023, discriminative loss: 7.242467880249023
Iteration 240, total loss: 7.184081077575684, discriminative loss: 7.184081077575684
Iteration 241, total loss: 7.157283306121826, discriminative loss: 7.157283306121826
Iteration 242, total loss: 7.275823593139648, discriminative loss: 7.275823593139648
Iteration 243, total loss: 7.107505798339844, discriminative loss: 7.107505798339844
Iteration 244, total loss: 7.255944728851318, discriminative loss: 7.255944728851318
Iteration 245, total loss: 7.252647876739502, discriminative loss: 7.252647876739502
Iteration 246, total loss: 7.135024070739746, discriminative loss: 7.135024070739746
Iteration 247, total loss: 7.124070644378662, discriminative loss: 7.124070644378662
Iteration 248, total loss: 7.0403151512146, discriminative loss: 7.0403151512146
Iteration 249, total loss: 7.324392318725586, discriminative loss: 7.324392318725586
Iteration 250, total loss: 7.13825798034668, discriminative loss: 7.13825798034668
Iteration 251, total loss: 7.120750904083252, discriminative loss: 7.120750904083252
Iteration 252, total loss: 7.0561370849609375, discriminative loss: 7.0561370849609375
Iteration 253, total loss: 7.170676231384277, discriminative loss: 7.170676231384277
Iteration 254, total loss: 7.108003616333008, discriminative loss: 7.108003616333008
Iteration 255, total loss: 6.983077049255371, discriminative loss: 6.983077049255371
Iteration 256, total loss: 7.275866985321045, discriminative loss: 7.275866985321045
Iteration 257, total loss: 7.357945442199707, discriminative loss: 7.357945442199707
Iteration 258, total loss: 7.3949737548828125, discriminative loss: 7.3949737548828125
Iteration 259, total loss: 7.132840633392334, discriminative loss: 7.132840633392334
Iteration 260, total loss: 7.146841049194336, discriminative loss: 7.146841049194336
Iteration 261, total loss: 7.3706159591674805, discriminative loss: 7.3706159591674805
Iteration 262, total loss: 6.995121479034424, discriminative loss: 6.995121479034424
Iteration 263, total loss: 7.189747333526611, discriminative loss: 7.189747333526611
Iteration 264, total loss: 7.29074239730835, discriminative loss: 7.29074239730835
Iteration 265, total loss: 7.066436290740967, discriminative loss: 7.066436290740967
Iteration 266, total loss: 7.058032035827637, discriminative loss: 7.058032035827637
Iteration 267, total loss: 7.0853190422058105, discriminative loss: 7.0853190422058105
Iteration 268, total loss: 7.256085395812988, discriminative loss: 7.256085395812988
Iteration 269, total loss: 7.096911430358887, discriminative loss: 7.096911430358887
Iteration 270, total loss: 7.04644775390625, discriminative loss: 7.04644775390625
Iteration 271, total loss: 7.161952495574951, discriminative loss: 7.161952495574951
Iteration 272, total loss: 6.958873748779297, discriminative loss: 6.958873748779297
Iteration 273, total loss: 7.2719340324401855, discriminative loss: 7.2719340324401855
Iteration 274, total loss: 7.15345573425293, discriminative loss: 7.15345573425293
Iteration 275, total loss: 7.004262924194336, discriminative loss: 7.004262924194336
Iteration 276, total loss: 7.139374732971191, discriminative loss: 7.139374732971191
Iteration 277, total loss: 7.0040693283081055, discriminative loss: 7.0040693283081055
Iteration 278, total loss: 7.085986137390137, discriminative loss: 7.085986137390137
Iteration 279, total loss: 7.195356369018555, discriminative loss: 7.195356369018555
Iteration 280, total loss: 7.082083702087402, discriminative loss: 7.082083702087402
Iteration 281, total loss: 7.040191650390625, discriminative loss: 7.040191650390625
Iteration 282, total loss: 7.1396565437316895, discriminative loss: 7.1396565437316895
Iteration 283, total loss: 7.118597507476807, discriminative loss: 7.118597507476807
Iteration 284, total loss: 7.406511306762695, discriminative loss: 7.406511306762695
Iteration 285, total loss: 7.202909469604492, discriminative loss: 7.202909469604492
Iteration 286, total loss: 7.116268157958984, discriminative loss: 7.116268157958984
Iteration 287, total loss: 6.949597358703613, discriminative loss: 6.949597358703613
Iteration 288, total loss: 7.114143371582031, discriminative loss: 7.114143371582031
Iteration 289, total loss: 6.9858598709106445, discriminative loss: 6.9858598709106445
Iteration 290, total loss: 7.211648941040039, discriminative loss: 7.211648941040039
Iteration 291, total loss: 7.162240028381348, discriminative loss: 7.162240028381348
Iteration 292, total loss: 7.151312828063965, discriminative loss: 7.151312828063965
Iteration 293, total loss: 7.185774326324463, discriminative loss: 7.185774326324463
Iteration 294, total loss: 7.217470645904541, discriminative loss: 7.217470645904541
Iteration 295, total loss: 7.219156265258789, discriminative loss: 7.219156265258789
Iteration 296, total loss: 7.163571834564209, discriminative loss: 7.163571834564209
Iteration 297, total loss: 7.193131446838379, discriminative loss: 7.193131446838379
Iteration 298, total loss: 7.42851448059082, discriminative loss: 7.42851448059082
Iteration 299, total loss: 7.254263877868652, discriminative loss: 7.254263877868652
Iteration 300, total loss: 7.196746349334717, discriminative loss: 7.196746349334717
Iteration 301, total loss: 7.1476545333862305, discriminative loss: 7.1476545333862305
Iteration 302, total loss: 7.108068943023682, discriminative loss: 7.108068943023682
Iteration 303, total loss: 7.108996391296387, discriminative loss: 7.108996391296387
Iteration 304, total loss: 7.039422512054443, discriminative loss: 7.039422512054443
Iteration 305, total loss: 7.213845252990723, discriminative loss: 7.213845252990723
Iteration 306, total loss: 7.288509845733643, discriminative loss: 7.288509845733643
Iteration 307, total loss: 7.125786781311035, discriminative loss: 7.125786781311035
Iteration 308, total loss: 7.158059597015381, discriminative loss: 7.158059597015381
Iteration 309, total loss: 7.263274192810059, discriminative loss: 7.263274192810059
Iteration 310, total loss: 7.225640773773193, discriminative loss: 7.225640773773193
Iteration 311, total loss: 7.096534729003906, discriminative loss: 7.096534729003906
Iteration 312, total loss: 7.231459617614746, discriminative loss: 7.231459617614746
Iteration 313, total loss: 7.133736610412598, discriminative loss: 7.133736610412598
Iteration 314, total loss: 7.095058917999268, discriminative loss: 7.095058917999268
Iteration 315, total loss: 7.212074279785156, discriminative loss: 7.212074279785156
Iteration 316, total loss: 7.215524196624756, discriminative loss: 7.215524196624756
Iteration 317, total loss: 7.263819694519043, discriminative loss: 7.263819694519043
Iteration 318, total loss: 7.017280578613281, discriminative loss: 7.017280578613281
Iteration 319, total loss: 7.192885875701904, discriminative loss: 7.192885875701904
Iteration 320, total loss: 7.083380222320557, discriminative loss: 7.083380222320557
Iteration 321, total loss: 7.176743984222412, discriminative loss: 7.176743984222412
Iteration 322, total loss: 7.410770893096924, discriminative loss: 7.410770893096924
Iteration 323, total loss: 7.249263286590576, discriminative loss: 7.249263286590576
Iteration 324, total loss: 7.136248588562012, discriminative loss: 7.136248588562012
Iteration 325, total loss: 7.082052707672119, discriminative loss: 7.082052707672119
Iteration 326, total loss: 7.322169780731201, discriminative loss: 7.322169780731201
Iteration 327, total loss: 7.2700276374816895, discriminative loss: 7.2700276374816895
Iteration 328, total loss: 7.183945655822754, discriminative loss: 7.183945655822754
Iteration 329, total loss: 7.118602752685547, discriminative loss: 7.118602752685547
Iteration 330, total loss: 7.131268501281738, discriminative loss: 7.131268501281738
Iteration 331, total loss: 7.286029815673828, discriminative loss: 7.286029815673828
Iteration 332, total loss: 7.1765642166137695, discriminative loss: 7.1765642166137695
Iteration 333, total loss: 7.229103088378906, discriminative loss: 7.229103088378906
Iteration 334, total loss: 7.056908130645752, discriminative loss: 7.056908130645752
Iteration 335, total loss: 6.954768180847168, discriminative loss: 6.954768180847168
Iteration 336, total loss: 7.222044944763184, discriminative loss: 7.222044944763184
Iteration 337, total loss: 7.209404945373535, discriminative loss: 7.209404945373535
Iteration 338, total loss: 7.189235210418701, discriminative loss: 7.189235210418701
Iteration 339, total loss: 7.136031150817871, discriminative loss: 7.136031150817871
Iteration 340, total loss: 7.218763828277588, discriminative loss: 7.218763828277588
Iteration 341, total loss: 7.205476760864258, discriminative loss: 7.205476760864258
Iteration 342, total loss: 7.300662517547607, discriminative loss: 7.300662517547607
Iteration 343, total loss: 7.146596908569336, discriminative loss: 7.146596908569336
Iteration 344, total loss: 7.1360578536987305, discriminative loss: 7.1360578536987305
Iteration 345, total loss: 7.036032676696777, discriminative loss: 7.036032676696777
Iteration 346, total loss: 7.2925872802734375, discriminative loss: 7.2925872802734375
Iteration 347, total loss: 7.190930366516113, discriminative loss: 7.190930366516113
Iteration 348, total loss: 7.0056867599487305, discriminative loss: 7.0056867599487305
Iteration 349, total loss: 7.096341133117676, discriminative loss: 7.096341133117676
Iteration 350, total loss: 7.276941776275635, discriminative loss: 7.276941776275635
Iteration 351, total loss: 7.1704230308532715, discriminative loss: 7.1704230308532715
Iteration 352, total loss: 7.226606369018555, discriminative loss: 7.226606369018555
Iteration 353, total loss: 7.224215507507324, discriminative loss: 7.224215507507324
Iteration 354, total loss: 7.2793378829956055, discriminative loss: 7.2793378829956055
Iteration 355, total loss: 7.362616539001465, discriminative loss: 7.362616539001465
Iteration 356, total loss: 7.143134593963623, discriminative loss: 7.143134593963623
Iteration 357, total loss: 7.016847610473633, discriminative loss: 7.016847610473633
Iteration 358, total loss: 7.08915901184082, discriminative loss: 7.08915901184082
Iteration 359, total loss: 7.365446090698242, discriminative loss: 7.365446090698242
Iteration 360, total loss: 7.2667131423950195, discriminative loss: 7.2667131423950195
Iteration 361, total loss: 7.218729019165039, discriminative loss: 7.218729019165039
Iteration 362, total loss: 7.106410026550293, discriminative loss: 7.106410026550293
Iteration 363, total loss: 7.0463666915893555, discriminative loss: 7.0463666915893555
Iteration 364, total loss: 7.197782039642334, discriminative loss: 7.197782039642334
Iteration 365, total loss: 7.128062725067139, discriminative loss: 7.128062725067139
Iteration 366, total loss: 7.242739677429199, discriminative loss: 7.242739677429199
Iteration 367, total loss: 7.170346260070801, discriminative loss: 7.170346260070801
Iteration 368, total loss: 7.204423904418945, discriminative loss: 7.204423904418945
Iteration 369, total loss: 7.319896221160889, discriminative loss: 7.319896221160889
Iteration 370, total loss: 7.2100067138671875, discriminative loss: 7.2100067138671875
Iteration 371, total loss: 7.137933731079102, discriminative loss: 7.137933731079102
Iteration 372, total loss: 7.112791061401367, discriminative loss: 7.112791061401367
Iteration 373, total loss: 7.195645332336426, discriminative loss: 7.195645332336426
Iteration 374, total loss: 7.143435001373291, discriminative loss: 7.143435001373291
Iteration 375, total loss: 7.306281566619873, discriminative loss: 7.306281566619873
Iteration 376, total loss: 7.2280659675598145, discriminative loss: 7.2280659675598145
Iteration 377, total loss: 7.141235828399658, discriminative loss: 7.141235828399658
Iteration 378, total loss: 7.091176509857178, discriminative loss: 7.091176509857178
Iteration 379, total loss: 7.194721221923828, discriminative loss: 7.194721221923828
Iteration 380, total loss: 7.164211750030518, discriminative loss: 7.164211750030518
Iteration 381, total loss: 7.155586242675781, discriminative loss: 7.155586242675781
Iteration 382, total loss: 7.204318523406982, discriminative loss: 7.204318523406982
Iteration 383, total loss: 7.297339916229248, discriminative loss: 7.297339916229248
Iteration 384, total loss: 7.040470123291016, discriminative loss: 7.040470123291016
Iteration 385, total loss: 7.163346290588379, discriminative loss: 7.163346290588379
Iteration 386, total loss: 7.22111701965332, discriminative loss: 7.22111701965332
Iteration 387, total loss: 7.16648530960083, discriminative loss: 7.16648530960083
Iteration 388, total loss: 7.091533660888672, discriminative loss: 7.091533660888672
Iteration 389, total loss: 7.0978312492370605, discriminative loss: 7.0978312492370605
Iteration 390, total loss: 6.984874248504639, discriminative loss: 6.984874248504639
Iteration 391, total loss: 7.179745674133301, discriminative loss: 7.179745674133301
Iteration 392, total loss: 7.11932373046875, discriminative loss: 7.11932373046875
Iteration 393, total loss: 7.110936164855957, discriminative loss: 7.110936164855957
Iteration 394, total loss: 7.259857177734375, discriminative loss: 7.259857177734375
Iteration 395, total loss: 7.153199195861816, discriminative loss: 7.153199195861816
Iteration 396, total loss: 7.1845703125, discriminative loss: 7.1845703125
Iteration 397, total loss: 7.2599711418151855, discriminative loss: 7.2599711418151855
Iteration 398, total loss: 7.101240634918213, discriminative loss: 7.101240634918213
Iteration 399, total loss: 7.142233848571777, discriminative loss: 7.142233848571777
Iteration 400, total loss: 7.263828754425049, discriminative loss: 7.263828754425049
Iteration 401, total loss: 7.13092041015625, discriminative loss: 7.13092041015625
Iteration 402, total loss: 7.154682159423828, discriminative loss: 7.154682159423828
Iteration 403, total loss: 7.078333854675293, discriminative loss: 7.078333854675293
Iteration 404, total loss: 7.033132553100586, discriminative loss: 7.033132553100586
Iteration 405, total loss: 7.099654197692871, discriminative loss: 7.099654197692871
Iteration 406, total loss: 7.131316184997559, discriminative loss: 7.131316184997559
Iteration 407, total loss: 7.25362491607666, discriminative loss: 7.25362491607666
Iteration 408, total loss: 7.185354232788086, discriminative loss: 7.185354232788086
Iteration 409, total loss: 7.109655380249023, discriminative loss: 7.109655380249023
Iteration 410, total loss: 7.1893463134765625, discriminative loss: 7.1893463134765625
Iteration 411, total loss: 7.191815376281738, discriminative loss: 7.191815376281738
Iteration 412, total loss: 7.170285224914551, discriminative loss: 7.170285224914551
Iteration 413, total loss: 7.319256782531738, discriminative loss: 7.319256782531738
Iteration 414, total loss: 7.121059417724609, discriminative loss: 7.121059417724609
Iteration 415, total loss: 7.044425964355469, discriminative loss: 7.044425964355469
Iteration 416, total loss: 7.136457443237305, discriminative loss: 7.136457443237305
Iteration 417, total loss: 7.298340320587158, discriminative loss: 7.298340320587158
Iteration 418, total loss: 7.257391929626465, discriminative loss: 7.257391929626465
Iteration 419, total loss: 7.180649757385254, discriminative loss: 7.180649757385254
Iteration 420, total loss: 7.242833137512207, discriminative loss: 7.242833137512207
Iteration 421, total loss: 7.058404922485352, discriminative loss: 7.058404922485352
Iteration 422, total loss: 7.140204429626465, discriminative loss: 7.140204429626465
Iteration 423, total loss: 7.203998565673828, discriminative loss: 7.203998565673828
Iteration 424, total loss: 7.277875900268555, discriminative loss: 7.277875900268555
Iteration 425, total loss: 7.051513671875, discriminative loss: 7.051513671875
Iteration 426, total loss: 7.098667621612549, discriminative loss: 7.098667621612549
Iteration 427, total loss: 7.163501739501953, discriminative loss: 7.163501739501953
Iteration 428, total loss: 7.247038841247559, discriminative loss: 7.247038841247559
Iteration 429, total loss: 6.996921539306641, discriminative loss: 6.996921539306641
Iteration 430, total loss: 7.166734218597412, discriminative loss: 7.166734218597412
Iteration 431, total loss: 7.266661643981934, discriminative loss: 7.266661643981934
Iteration 432, total loss: 7.188104629516602, discriminative loss: 7.188104629516602
Iteration 433, total loss: 6.986201763153076, discriminative loss: 6.986201763153076
Iteration 434, total loss: 7.209521770477295, discriminative loss: 7.209521770477295
Iteration 435, total loss: 7.1880927085876465, discriminative loss: 7.1880927085876465
Iteration 436, total loss: 7.068878173828125, discriminative loss: 7.068878173828125
Iteration 437, total loss: 7.235013008117676, discriminative loss: 7.235013008117676
Iteration 438, total loss: 7.233083724975586, discriminative loss: 7.233083724975586
Iteration 439, total loss: 7.330501556396484, discriminative loss: 7.330501556396484
Iteration 440, total loss: 7.215503692626953, discriminative loss: 7.215503692626953
Iteration 441, total loss: 7.189615726470947, discriminative loss: 7.189615726470947
Iteration 442, total loss: 7.217663764953613, discriminative loss: 7.217663764953613
Iteration 443, total loss: 7.305324077606201, discriminative loss: 7.305324077606201
Iteration 444, total loss: 7.130226135253906, discriminative loss: 7.130226135253906
Iteration 445, total loss: 7.282769203186035, discriminative loss: 7.282769203186035
Iteration 446, total loss: 7.211169242858887, discriminative loss: 7.211169242858887
Iteration 447, total loss: 7.016859531402588, discriminative loss: 7.016859531402588
Iteration 448, total loss: 7.216691017150879, discriminative loss: 7.216691017150879
Iteration 449, total loss: 7.278998374938965, discriminative loss: 7.278998374938965
Iteration 450, total loss: 7.1936774253845215, discriminative loss: 7.1936774253845215
Iteration 451, total loss: 7.162931442260742, discriminative loss: 7.162931442260742
Iteration 452, total loss: 7.152131080627441, discriminative loss: 7.152131080627441
Iteration 453, total loss: 7.21945858001709, discriminative loss: 7.21945858001709
Iteration 454, total loss: 7.142324924468994, discriminative loss: 7.142324924468994
Iteration 455, total loss: 7.144537925720215, discriminative loss: 7.144537925720215
Iteration 456, total loss: 7.138875961303711, discriminative loss: 7.138875961303711
Iteration 457, total loss: 7.129398345947266, discriminative loss: 7.129398345947266
Iteration 458, total loss: 7.249249458312988, discriminative loss: 7.249249458312988
Iteration 459, total loss: 7.2270097732543945, discriminative loss: 7.2270097732543945
Iteration 460, total loss: 7.136895179748535, discriminative loss: 7.136895179748535
Iteration 461, total loss: 7.2692413330078125, discriminative loss: 7.2692413330078125
Iteration 462, total loss: 7.194337844848633, discriminative loss: 7.194337844848633
Iteration 463, total loss: 7.1336822509765625, discriminative loss: 7.1336822509765625
Iteration 464, total loss: 7.242700099945068, discriminative loss: 7.242700099945068
Iteration 465, total loss: 7.051033973693848, discriminative loss: 7.051033973693848
Iteration 466, total loss: 7.151453018188477, discriminative loss: 7.151453018188477
Iteration 467, total loss: 7.095358371734619, discriminative loss: 7.095358371734619
Iteration 468, total loss: 6.9660258293151855, discriminative loss: 6.9660258293151855
Iteration 469, total loss: 7.248594284057617, discriminative loss: 7.248594284057617
Iteration 470, total loss: 7.226913928985596, discriminative loss: 7.226913928985596
Iteration 471, total loss: 7.305611610412598, discriminative loss: 7.305611610412598
Iteration 472, total loss: 7.144420623779297, discriminative loss: 7.144420623779297
Iteration 473, total loss: 7.211620807647705, discriminative loss: 7.211620807647705
Iteration 474, total loss: 7.307676315307617, discriminative loss: 7.307676315307617
Iteration 475, total loss: 7.31355619430542, discriminative loss: 7.31355619430542
Iteration 476, total loss: 7.192622184753418, discriminative loss: 7.192622184753418
Iteration 477, total loss: 7.044018268585205, discriminative loss: 7.044018268585205
Iteration 478, total loss: 7.096853256225586, discriminative loss: 7.096853256225586
Iteration 479, total loss: 7.331236839294434, discriminative loss: 7.331236839294434
Iteration 480, total loss: 7.241377353668213, discriminative loss: 7.241377353668213
Iteration 481, total loss: 7.157878398895264, discriminative loss: 7.157878398895264
Iteration 482, total loss: 7.062502861022949, discriminative loss: 7.062502861022949
Iteration 483, total loss: 7.181640625, discriminative loss: 7.181640625
Iteration 484, total loss: 7.053072929382324, discriminative loss: 7.053072929382324
Iteration 485, total loss: 7.212839126586914, discriminative loss: 7.212839126586914
Iteration 486, total loss: 7.092235565185547, discriminative loss: 7.092235565185547
Iteration 487, total loss: 7.199552536010742, discriminative loss: 7.199552536010742
Iteration 488, total loss: 7.125147819519043, discriminative loss: 7.125147819519043
Iteration 489, total loss: 7.200143337249756, discriminative loss: 7.200143337249756
Iteration 490, total loss: 7.031397819519043, discriminative loss: 7.031397819519043
Iteration 491, total loss: 7.16419792175293, discriminative loss: 7.16419792175293
Iteration 492, total loss: 7.171236038208008, discriminative loss: 7.171236038208008
Iteration 493, total loss: 7.135577201843262, discriminative loss: 7.135577201843262
Iteration 494, total loss: 7.231337547302246, discriminative loss: 7.231337547302246
Iteration 495, total loss: 7.036243438720703, discriminative loss: 7.036243438720703
Iteration 496, total loss: 7.141932487487793, discriminative loss: 7.141932487487793
Iteration 497, total loss: 7.10133171081543, discriminative loss: 7.10133171081543
Iteration 498, total loss: 7.231137275695801, discriminative loss: 7.231137275695801
Iteration 499, total loss: 7.210177898406982, discriminative loss: 7.210177898406982
Iteration 500, total loss: 7.045327663421631, discriminative loss: 7.045327663421631
Iteration 501, total loss: 7.072187423706055, discriminative loss: 7.072187423706055
Iteration 502, total loss: 7.350112438201904, discriminative loss: 7.350112438201904
Iteration 503, total loss: 7.172571182250977, discriminative loss: 7.172571182250977
Iteration 504, total loss: 6.947084903717041, discriminative loss: 6.947084903717041
Iteration 505, total loss: 7.245707988739014, discriminative loss: 7.245707988739014
Iteration 506, total loss: 7.2114763259887695, discriminative loss: 7.2114763259887695
Iteration 507, total loss: 7.143035888671875, discriminative loss: 7.143035888671875
Iteration 508, total loss: 7.317102432250977, discriminative loss: 7.317102432250977
Iteration 509, total loss: 7.2557196617126465, discriminative loss: 7.2557196617126465
Iteration 510, total loss: 7.105611324310303, discriminative loss: 7.105611324310303
Iteration 511, total loss: 7.055666446685791, discriminative loss: 7.055666446685791
Iteration 512, total loss: 7.177574157714844, discriminative loss: 7.177574157714844
Iteration 513, total loss: 7.341575622558594, discriminative loss: 7.341575622558594
Iteration 514, total loss: 7.26228666305542, discriminative loss: 7.26228666305542
Iteration 515, total loss: 7.102163791656494, discriminative loss: 7.102163791656494
Iteration 516, total loss: 7.00166130065918, discriminative loss: 7.00166130065918
Iteration 517, total loss: 7.115535736083984, discriminative loss: 7.115535736083984
Iteration 518, total loss: 7.113430976867676, discriminative loss: 7.113430976867676
Iteration 519, total loss: 7.148368835449219, discriminative loss: 7.148368835449219
Iteration 520, total loss: 7.142618179321289, discriminative loss: 7.142618179321289
Iteration 521, total loss: 7.242636680603027, discriminative loss: 7.242636680603027
Iteration 522, total loss: 7.168832778930664, discriminative loss: 7.168832778930664
Iteration 523, total loss: 7.123055458068848, discriminative loss: 7.123055458068848
Iteration 524, total loss: 7.170167922973633, discriminative loss: 7.170167922973633
Iteration 525, total loss: 7.172906875610352, discriminative loss: 7.172906875610352
Iteration 526, total loss: 7.2909836769104, discriminative loss: 7.2909836769104
Iteration 527, total loss: 7.179935932159424, discriminative loss: 7.179935932159424
Iteration 528, total loss: 7.190647125244141, discriminative loss: 7.190647125244141
Iteration 529, total loss: 7.201361179351807, discriminative loss: 7.201361179351807
Iteration 530, total loss: 7.129199981689453, discriminative loss: 7.129199981689453
Iteration 531, total loss: 7.088929176330566, discriminative loss: 7.088929176330566
Iteration 532, total loss: 7.172703742980957, discriminative loss: 7.172703742980957
Iteration 533, total loss: 7.152544021606445, discriminative loss: 7.152544021606445
Iteration 534, total loss: 7.247060298919678, discriminative loss: 7.247060298919678
Iteration 535, total loss: 7.2098588943481445, discriminative loss: 7.2098588943481445
Iteration 536, total loss: 7.154529571533203, discriminative loss: 7.154529571533203
Iteration 537, total loss: 7.129376411437988, discriminative loss: 7.129376411437988
Iteration 538, total loss: 7.123690128326416, discriminative loss: 7.123690128326416
Iteration 539, total loss: 7.378935813903809, discriminative loss: 7.378935813903809
Iteration 540, total loss: 7.0848283767700195, discriminative loss: 7.0848283767700195
Iteration 541, total loss: 6.86464262008667, discriminative loss: 6.86464262008667
Iteration 542, total loss: 7.208669662475586, discriminative loss: 7.208669662475586
Iteration 543, total loss: 7.155359745025635, discriminative loss: 7.155359745025635
Iteration 544, total loss: 7.315153121948242, discriminative loss: 7.315153121948242
Iteration 545, total loss: 7.314020156860352, discriminative loss: 7.314020156860352
Iteration 546, total loss: 7.148031234741211, discriminative loss: 7.148031234741211
Iteration 547, total loss: 7.169873237609863, discriminative loss: 7.169873237609863
Iteration 548, total loss: 7.256325721740723, discriminative loss: 7.256325721740723
Iteration 549, total loss: 7.181058883666992, discriminative loss: 7.181058883666992
Iteration 550, total loss: 7.309235095977783, discriminative loss: 7.309235095977783
Iteration 551, total loss: 7.151615142822266, discriminative loss: 7.151615142822266
Iteration 552, total loss: 7.080695629119873, discriminative loss: 7.080695629119873
Iteration 553, total loss: 7.139326572418213, discriminative loss: 7.139326572418213
Iteration 554, total loss: 6.9930853843688965, discriminative loss: 6.9930853843688965
Iteration 555, total loss: 6.955343246459961, discriminative loss: 6.955343246459961
Iteration 556, total loss: 7.055844306945801, discriminative loss: 7.055844306945801
Iteration 557, total loss: 7.248570442199707, discriminative loss: 7.248570442199707
Iteration 558, total loss: 7.147411823272705, discriminative loss: 7.147411823272705
Iteration 559, total loss: 6.9575276374816895, discriminative loss: 6.9575276374816895
Iteration 560, total loss: 7.02260684967041, discriminative loss: 7.02260684967041
Iteration 561, total loss: 7.138517379760742, discriminative loss: 7.138517379760742
Iteration 562, total loss: 7.20881462097168, discriminative loss: 7.20881462097168
Iteration 563, total loss: 7.302774429321289, discriminative loss: 7.302774429321289
Iteration 564, total loss: 7.183526039123535, discriminative loss: 7.183526039123535
Iteration 565, total loss: 7.363220691680908, discriminative loss: 7.363220691680908
Iteration 566, total loss: 7.171547889709473, discriminative loss: 7.171547889709473
Iteration 567, total loss: 7.293820858001709, discriminative loss: 7.293820858001709
Iteration 568, total loss: 7.116600036621094, discriminative loss: 7.116600036621094
Iteration 569, total loss: 7.013361930847168, discriminative loss: 7.013361930847168
Iteration 570, total loss: 7.11810302734375, discriminative loss: 7.11810302734375
Iteration 571, total loss: 7.1800127029418945, discriminative loss: 7.1800127029418945
Iteration 572, total loss: 7.122994422912598, discriminative loss: 7.122994422912598
Iteration 573, total loss: 7.185445785522461, discriminative loss: 7.185445785522461
Iteration 574, total loss: 7.229884147644043, discriminative loss: 7.229884147644043
Iteration 575, total loss: 7.240897178649902, discriminative loss: 7.240897178649902
Iteration 576, total loss: 7.211813926696777, discriminative loss: 7.211813926696777
Iteration 577, total loss: 7.0789079666137695, discriminative loss: 7.0789079666137695
Iteration 578, total loss: 7.125763893127441, discriminative loss: 7.125763893127441
Iteration 579, total loss: 7.256340980529785, discriminative loss: 7.256340980529785
Iteration 580, total loss: 7.262775897979736, discriminative loss: 7.262775897979736
Iteration 581, total loss: 7.306863784790039, discriminative loss: 7.306863784790039
Iteration 582, total loss: 7.359500408172607, discriminative loss: 7.359500408172607
Iteration 583, total loss: 7.205845832824707, discriminative loss: 7.205845832824707
Iteration 584, total loss: 7.232791900634766, discriminative loss: 7.232791900634766
Iteration 585, total loss: 7.267756462097168, discriminative loss: 7.267756462097168
Iteration 586, total loss: 7.159656047821045, discriminative loss: 7.159656047821045
Iteration 587, total loss: 7.198531627655029, discriminative loss: 7.198531627655029
Iteration 588, total loss: 7.07820987701416, discriminative loss: 7.07820987701416
Iteration 589, total loss: 7.22849178314209, discriminative loss: 7.22849178314209
Iteration 590, total loss: 7.113425254821777, discriminative loss: 7.113425254821777
Iteration 591, total loss: 7.1803717613220215, discriminative loss: 7.1803717613220215
Iteration 592, total loss: 7.100984573364258, discriminative loss: 7.100984573364258
Iteration 593, total loss: 7.093901634216309, discriminative loss: 7.093901634216309
Iteration 594, total loss: 7.2305145263671875, discriminative loss: 7.2305145263671875
Iteration 595, total loss: 7.074353218078613, discriminative loss: 7.074353218078613
Iteration 596, total loss: 7.031510353088379, discriminative loss: 7.031510353088379
Iteration 597, total loss: 7.130955219268799, discriminative loss: 7.130955219268799
Iteration 598, total loss: 7.25452995300293, discriminative loss: 7.25452995300293
Iteration 599, total loss: 7.295186996459961, discriminative loss: 7.295186996459961
Iteration 600, total loss: 7.145064830780029, discriminative loss: 7.145064830780029
Iteration 601, total loss: 7.255620002746582, discriminative loss: 7.255620002746582
Iteration 602, total loss: 7.2158732414245605, discriminative loss: 7.2158732414245605
Iteration 603, total loss: 7.096075057983398, discriminative loss: 7.096075057983398
Iteration 604, total loss: 7.20610237121582, discriminative loss: 7.20610237121582
Iteration 605, total loss: 7.080243110656738, discriminative loss: 7.080243110656738
Iteration 606, total loss: 7.289743900299072, discriminative loss: 7.289743900299072
Iteration 607, total loss: 7.119858741760254, discriminative loss: 7.119858741760254
Iteration 608, total loss: 7.179542541503906, discriminative loss: 7.179542541503906
Iteration 609, total loss: 7.221611022949219, discriminative loss: 7.221611022949219
Iteration 610, total loss: 7.172161102294922, discriminative loss: 7.172161102294922
Iteration 611, total loss: 7.260186195373535, discriminative loss: 7.260186195373535
Iteration 612, total loss: 7.184696197509766, discriminative loss: 7.184696197509766
Iteration 613, total loss: 7.1098737716674805, discriminative loss: 7.1098737716674805
Iteration 614, total loss: 7.210718154907227, discriminative loss: 7.210718154907227
Iteration 615, total loss: 7.251648426055908, discriminative loss: 7.251648426055908
Iteration 616, total loss: 7.162867546081543, discriminative loss: 7.162867546081543
Iteration 617, total loss: 7.051029205322266, discriminative loss: 7.051029205322266
Iteration 618, total loss: 7.028371810913086, discriminative loss: 7.028371810913086
Iteration 619, total loss: 7.134410858154297, discriminative loss: 7.134410858154297
Iteration 620, total loss: 7.062167644500732, discriminative loss: 7.062167644500732
Iteration 621, total loss: 7.21858024597168, discriminative loss: 7.21858024597168
Iteration 622, total loss: 7.171232223510742, discriminative loss: 7.171232223510742
Iteration 623, total loss: 7.186435222625732, discriminative loss: 7.186435222625732
Iteration 624, total loss: 7.125507354736328, discriminative loss: 7.125507354736328
Iteration 625, total loss: 6.983644485473633, discriminative loss: 6.983644485473633
Iteration 626, total loss: 7.330679893493652, discriminative loss: 7.330679893493652
Iteration 627, total loss: 7.003627777099609, discriminative loss: 7.003627777099609
Iteration 628, total loss: 7.201562881469727, discriminative loss: 7.201562881469727
Iteration 629, total loss: 7.077434539794922, discriminative loss: 7.077434539794922
Iteration 630, total loss: 7.045609474182129, discriminative loss: 7.045609474182129
Iteration 631, total loss: 7.308133125305176, discriminative loss: 7.308133125305176
Iteration 632, total loss: 7.083241939544678, discriminative loss: 7.083241939544678
Iteration 633, total loss: 7.124911308288574, discriminative loss: 7.124911308288574
Iteration 634, total loss: 7.20151424407959, discriminative loss: 7.20151424407959
Iteration 635, total loss: 7.163931369781494, discriminative loss: 7.163931369781494
Iteration 636, total loss: 6.991076946258545, discriminative loss: 6.991076946258545
Iteration 637, total loss: 7.005923748016357, discriminative loss: 7.005923748016357
Iteration 638, total loss: 7.2334065437316895, discriminative loss: 7.2334065437316895
Iteration 639, total loss: 7.165708541870117, discriminative loss: 7.165708541870117
Iteration 640, total loss: 7.432186126708984, discriminative loss: 7.432186126708984
Iteration 641, total loss: 7.245338439941406, discriminative loss: 7.245338439941406
Iteration 642, total loss: 7.253222465515137, discriminative loss: 7.253222465515137
Iteration 643, total loss: 7.182999134063721, discriminative loss: 7.182999134063721
Iteration 644, total loss: 7.22350549697876, discriminative loss: 7.22350549697876
Iteration 645, total loss: 7.250490188598633, discriminative loss: 7.250490188598633
Iteration 646, total loss: 7.189310550689697, discriminative loss: 7.189310550689697
Iteration 647, total loss: 7.23679780960083, discriminative loss: 7.23679780960083
Iteration 648, total loss: 7.200001239776611, discriminative loss: 7.200001239776611
Iteration 649, total loss: 7.182706832885742, discriminative loss: 7.182706832885742
Iteration 650, total loss: 7.182586669921875, discriminative loss: 7.182586669921875
Iteration 651, total loss: 7.153303146362305, discriminative loss: 7.153303146362305
Iteration 652, total loss: 7.227896690368652, discriminative loss: 7.227896690368652
Iteration 653, total loss: 7.199283599853516, discriminative loss: 7.199283599853516
Iteration 654, total loss: 7.161971569061279, discriminative loss: 7.161971569061279
Iteration 655, total loss: 7.365457057952881, discriminative loss: 7.365457057952881
Iteration 656, total loss: 7.176973342895508, discriminative loss: 7.176973342895508
Iteration 657, total loss: 7.25522518157959, discriminative loss: 7.25522518157959
Iteration 658, total loss: 7.100050449371338, discriminative loss: 7.100050449371338
Iteration 659, total loss: 7.255634307861328, discriminative loss: 7.255634307861328
Iteration 660, total loss: 7.156122207641602, discriminative loss: 7.156122207641602
Iteration 661, total loss: 7.194279670715332, discriminative loss: 7.194279670715332
Iteration 662, total loss: 7.091770172119141, discriminative loss: 7.091770172119141
Iteration 663, total loss: 7.24581241607666, discriminative loss: 7.24581241607666
Training completed
Model saved to file: /home/im-zbox2/harpreet/github/anomaly-svm-study/deep_one_class_features/results/trained_model_a.h5
